{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress, not a complete example.\n",
    "\n",
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST example (data downloading etc.) is based on Google's https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "# See LICENSE for details.\n",
    "\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "WORK_DIRECTORY = 'data'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100  # Number of steps between evaluations.\n",
    "\n",
    "EMBEDDING_SIZE = 10\n",
    "NUM_INTERNAL_CONVS = 5\n",
    "NUM_UNROLL_STEPS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "def maybe_download(filename):\n",
    "  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "  if not tf.gfile.Exists(WORK_DIRECTORY):\n",
    "    tf.gfile.MakeDirs(WORK_DIRECTORY)\n",
    "  filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "  if not tf.gfile.Exists(filepath):\n",
    "    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "    with tf.gfile.GFile(filepath) as f:\n",
    "      size = f.size()\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "  return filepath\n",
    "\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "\n",
    "  Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "  \"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n",
    "  return labels\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def error_rate(predictions, labels):\n",
    "  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\n",
    "  argmax = numpy.argmax(predictions, 1)\n",
    "  print(Counter(argmax).most_common())\n",
    "  return 100.0 - (\n",
    "      100.0 *\n",
    "      numpy.sum(argmax == labels) /\n",
    "      predictions.shape[0])\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "# Generate a validation set.\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, ...]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "train_size = train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(input_images, training):\n",
    "    x = input_images\n",
    "    x = tf.layers.conv2d(x, filters=16, kernel_size=[5,5], strides=2,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, scale=False, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3,3], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, scale=False, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3,3], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, scale=False, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3,3], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "def model_step(input_images, prior, batch_size):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    prior_embeddings = tf.get_variable(\"prior_embeddings\",\n",
    "                                        shape=[NUM_LABELS, EMBEDDING_SIZE],\n",
    "                                        initializer=tf.random_uniform_initializer(\n",
    "                                            minval=-1.0/numpy.sqrt(NUM_LABELS), maxval=1.0/numpy.sqrt(NUM_LABELS)))\n",
    "    embedding_features = tf.matmul(prior, prior_embeddings)\n",
    "    for i in range(4):\n",
    "        embedding_features = embedding_features + tf.layers.dense(\n",
    "            embedding_features, EMBEDDING_SIZE, use_bias=False, activation=tf.nn.relu)\n",
    "    \n",
    "    def get_dynamic_weights(weights_shape):\n",
    "        num_weights = numpy.prod(weights_shape[1:])\n",
    "        dynamic_weights_flat = tf.layers.dense(embedding_features, num_weights)\n",
    "        dynamic_weights = tf.reshape(dynamic_weights_flat, weights_shape)\n",
    "        dynamic_weights.set_shape(weights_shape)\n",
    "        return dynamic_weights\n",
    "    \n",
    "    conv1_weights = get_dynamic_weights([batch_size, 1, 1, 128, EMBEDDING_SIZE])\n",
    "    conv2_weights = [get_dynamic_weights([batch_size, 2, 2, EMBEDDING_SIZE, EMBEDDING_SIZE])\n",
    "                     for _ in range(NUM_INTERNAL_CONVS)]\n",
    "    conv3_weights = get_dynamic_weights([batch_size, 1, 1, EMBEDDING_SIZE, NUM_LABELS])\n",
    "    conv3_biases = get_dynamic_weights([batch_size, NUM_LABELS])\n",
    "    \n",
    "    logits_lst, posteriors_lst = [], []\n",
    "    for elm in range(batch_size):\n",
    "        conv = tf.nn.conv2d([input_images[elm]],\n",
    "                            conv1_weights[elm],\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding='VALID')\n",
    "        relu = tf.nn.relu(conv)\n",
    "        for i in range(NUM_INTERNAL_CONVS):\n",
    "            conv = tf.nn.conv2d(relu,\n",
    "                            conv2_weights[i][elm],\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding='SAME')\n",
    "            relu = tf.nn.relu(conv) + relu\n",
    "        conv = tf.nn.conv2d(relu,\n",
    "                            conv3_weights[elm],\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding='VALID')\n",
    "        conv_shape = conv.get_shape()\n",
    "        logits = tf.nn.avg_pool(conv, ksize=[1, conv_shape[1], conv_shape[2], 1],\n",
    "                                strides=[1, 1, 1, 1], padding=\"VALID\") + conv3_biases[elm]\n",
    "        logits = tf.squeeze(logits, axis=[1, 2])\n",
    "        posteriors = tf.nn.softmax(logits)\n",
    "        logits_lst.append(logits)\n",
    "        posteriors_lst.append(posteriors)\n",
    "    return tf.concat(logits_lst, axis=0), tf.concat(posteriors_lst, axis=0)\n",
    "\n",
    "def apply(input_images, training):\n",
    "    results = []\n",
    "    loss = 0.0\n",
    "    conv_features = feature_extractor(input_images, training=training)\n",
    "    batch_size = conv_features.get_shape()[0]  # HyperNet operates on single images only\n",
    "    priors = numpy.array([[1/NUM_LABELS for _ in range(NUM_LABELS)] for _ in range(batch_size)],\n",
    "                         dtype=numpy.float32)\n",
    "    for step in range(NUM_UNROLL_STEPS):\n",
    "        logits, posteriors = model_step(conv_features, priors, batch_size)\n",
    "        priors = posteriors\n",
    "        results.append((logits, posteriors))\n",
    "        loss += (1.0 if step + 1 == NUM_UNROLL_STEPS else 0.1) * tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=train_labels_node, logits=logits))\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Step 0 (epoch 0.00), 772.7 ms\n",
      "Minibatch loss: 4.361, learning rate: 0.001000\n",
      "[(9, 64)]\n",
      "Minibatch error: 89.1%\n",
      "[(9, 5000)]\n",
      "Validation error: 90.1%\n",
      "Step 100 (epoch 0.12), 1015.1 ms\n",
      "Minibatch loss: 2.254, learning rate: 0.001000\n",
      "[(4, 10), (7, 10), (0, 9), (1, 9), (3, 8), (2, 7), (6, 6), (8, 4), (9, 1)]\n",
      "Minibatch error: 21.9%\n",
      "[(7, 3515), (1, 1485)]\n",
      "Validation error: 82.1%\n",
      "Step 200 (epoch 0.23), 923.0 ms\n",
      "Minibatch loss: 1.790, learning rate: 0.001000\n",
      "[(1, 11), (4, 10), (9, 9), (2, 7), (6, 7), (8, 7), (7, 6), (5, 3), (0, 2), (3, 2)]\n",
      "Minibatch error: 18.8%\n",
      "[(7, 2982), (1, 1233), (4, 386), (9, 295), (3, 104)]\n",
      "Validation error: 74.1%\n",
      "Step 300 (epoch 0.35), 927.9 ms\n",
      "Minibatch loss: 1.064, learning rate: 0.001000\n",
      "[(2, 9), (6, 8), (9, 8), (3, 7), (7, 7), (1, 6), (4, 6), (8, 6), (5, 4), (0, 3)]\n",
      "Minibatch error: 10.9%\n",
      "[(4, 977), (5, 661), (7, 655), (9, 578), (3, 559), (1, 532), (6, 387), (0, 348), (2, 301), (8, 2)]\n",
      "Validation error: 25.2%\n",
      "Step 400 (epoch 0.47), 937.2 ms\n",
      "Minibatch loss: 1.309, learning rate: 0.001000\n",
      "[(1, 8), (3, 8), (2, 7), (7, 7), (8, 7), (9, 7), (0, 6), (6, 6), (4, 5), (5, 3)]\n",
      "Minibatch error: 7.8%\n",
      "[(3, 1051), (7, 740), (1, 668), (9, 500), (4, 447), (0, 442), (6, 424), (5, 378), (2, 273), (8, 77)]\n",
      "Validation error: 21.7%\n",
      "Step 500 (epoch 0.58), 914.8 ms\n",
      "Minibatch loss: 1.133, learning rate: 0.001000\n",
      "[(1, 11), (3, 8), (2, 7), (6, 7), (9, 7), (5, 6), (8, 6), (7, 5), (0, 4), (4, 3)]\n",
      "Minibatch error: 6.2%\n",
      "[(3, 630), (1, 551), (2, 523), (6, 508), (0, 499), (8, 492), (5, 487), (9, 451), (7, 447), (4, 412)]\n",
      "Validation error: 10.1%\n",
      "Step 600 (epoch 0.70), 926.6 ms\n",
      "Minibatch loss: 0.819, learning rate: 0.001000\n",
      "[(3, 9), (0, 7), (1, 7), (2, 7), (5, 7), (6, 7), (7, 6), (9, 6), (8, 5), (4, 3)]\n",
      "Minibatch error: 4.7%\n",
      "[(4, 572), (7, 567), (1, 563), (9, 508), (6, 484), (0, 478), (3, 474), (8, 474), (2, 440), (5, 440)]\n",
      "Validation error: 4.2%\n",
      "Step 700 (epoch 0.81), 930.1 ms\n",
      "Minibatch loss: 0.518, learning rate: 0.001000\n",
      "[(1, 9), (3, 8), (8, 8), (2, 6), (5, 6), (6, 6), (7, 6), (0, 5), (4, 5), (9, 5)]\n",
      "Minibatch error: 3.1%\n",
      "[(7, 586), (1, 537), (9, 526), (4, 510), (2, 499), (6, 487), (8, 481), (3, 473), (5, 454), (0, 447)]\n",
      "Validation error: 4.3%\n",
      "Step 800 (epoch 0.93), 949.2 ms\n",
      "Minibatch loss: 0.525, learning rate: 0.001000\n",
      "[(5, 10), (9, 10), (0, 7), (2, 7), (3, 6), (1, 5), (4, 5), (6, 5), (7, 5), (8, 4)]\n",
      "Minibatch error: 6.2%\n",
      "[(7, 586), (1, 581), (4, 520), (9, 517), (3, 512), (6, 481), (0, 471), (5, 469), (2, 443), (8, 420)]\n",
      "Validation error: 5.2%\n",
      "Step 900 (epoch 1.05), 932.9 ms\n",
      "Minibatch loss: 0.286, learning rate: 0.000950\n",
      "[(0, 9), (9, 9), (1, 7), (3, 7), (4, 7), (6, 7), (8, 6), (2, 5), (7, 5), (5, 2)]\n",
      "Minibatch error: 1.6%\n",
      "[(7, 565), (1, 544), (4, 526), (6, 511), (8, 511), (9, 486), (2, 477), (3, 466), (0, 457), (5, 457)]\n",
      "Validation error: 3.5%\n",
      "Step 1000 (epoch 1.16), 930.2 ms\n",
      "Minibatch loss: 0.246, learning rate: 0.000950\n",
      "[(2, 10), (5, 8), (7, 8), (3, 7), (1, 6), (4, 6), (9, 6), (0, 5), (6, 5), (8, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 557), (4, 555), (7, 532), (2, 516), (6, 509), (3, 499), (9, 469), (0, 468), (8, 464), (5, 431)]\n",
      "Validation error: 3.0%\n",
      "Step 1100 (epoch 1.28), 911.6 ms\n",
      "Minibatch loss: 0.190, learning rate: 0.000950\n",
      "[(2, 12), (4, 8), (6, 8), (0, 7), (8, 7), (7, 6), (9, 6), (1, 4), (3, 4), (5, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(4, 572), (1, 561), (7, 553), (2, 506), (6, 503), (3, 482), (9, 472), (0, 463), (5, 444), (8, 444)]\n",
      "Validation error: 3.3%\n",
      "Step 1200 (epoch 1.40), 947.7 ms\n",
      "Minibatch loss: 0.598, learning rate: 0.000950\n",
      "[(5, 9), (1, 8), (4, 8), (9, 8), (2, 7), (6, 7), (3, 5), (7, 5), (0, 4), (8, 3)]\n",
      "Minibatch error: 3.1%\n",
      "[(7, 592), (4, 590), (2, 525), (6, 521), (8, 499), (1, 497), (0, 471), (3, 467), (5, 458), (9, 380)]\n",
      "Validation error: 6.1%\n",
      "Step 1300 (epoch 1.51), 931.1 ms\n",
      "Minibatch loss: 0.223, learning rate: 0.000950\n",
      "[(1, 8), (4, 8), (8, 8), (7, 7), (9, 7), (5, 6), (6, 6), (0, 5), (3, 5), (2, 4)]\n",
      "Minibatch error: 3.1%\n",
      "[(6, 551), (1, 542), (7, 541), (4, 535), (2, 496), (3, 487), (9, 482), (0, 457), (5, 457), (8, 452)]\n",
      "Validation error: 3.2%\n",
      "Step 1400 (epoch 1.63), 937.1 ms\n",
      "Minibatch loss: 0.237, learning rate: 0.000950\n",
      "[(2, 8), (3, 8), (0, 7), (1, 7), (4, 7), (5, 7), (9, 7), (6, 6), (7, 5), (8, 2)]\n",
      "Minibatch error: 3.1%\n",
      "[(1, 571), (7, 540), (9, 522), (6, 512), (3, 500), (2, 490), (0, 489), (4, 479), (8, 450), (5, 447)]\n",
      "Validation error: 3.3%\n",
      "Step 1500 (epoch 1.75), 913.4 ms\n",
      "Minibatch loss: 0.127, learning rate: 0.000950\n",
      "[(3, 9), (1, 8), (2, 7), (6, 7), (7, 7), (9, 7), (0, 5), (5, 5), (8, 5), (4, 4)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 558), (7, 555), (4, 534), (3, 528), (2, 526), (6, 497), (9, 492), (0, 465), (8, 426), (5, 419)]\n",
      "Validation error: 3.0%\n",
      "Step 1600 (epoch 1.86), 922.5 ms\n",
      "Minibatch loss: 0.115, learning rate: 0.000950\n",
      "[(7, 11), (6, 10), (8, 8), (4, 6), (9, 6), (1, 5), (2, 5), (5, 5), (0, 4), (3, 4)]\n",
      "Minibatch error: 1.6%\n",
      "[(8, 572), (7, 567), (1, 536), (2, 509), (9, 506), (4, 499), (0, 480), (3, 480), (6, 432), (5, 419)]\n",
      "Validation error: 4.4%\n",
      "Step 1700 (epoch 1.98), 923.0 ms\n",
      "Minibatch loss: 0.023, learning rate: 0.000950\n",
      "[(1, 10), (4, 7), (6, 7), (7, 7), (0, 6), (5, 6), (9, 6), (2, 5), (3, 5), (8, 5)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 569), (7, 554), (3, 536), (9, 519), (6, 502), (4, 484), (0, 473), (2, 472), (8, 446), (5, 445)]\n",
      "Validation error: 3.6%\n",
      "Step 1800 (epoch 2.09), 936.5 ms\n",
      "Minibatch loss: 0.048, learning rate: 0.000902\n",
      "[(0, 10), (1, 8), (3, 8), (6, 7), (9, 7), (4, 6), (5, 6), (2, 4), (7, 4), (8, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 583), (7, 555), (4, 547), (0, 502), (6, 491), (2, 490), (3, 486), (9, 481), (5, 433), (8, 432)]\n",
      "Validation error: 2.5%\n",
      "Step 1900 (epoch 2.21), 936.7 ms\n",
      "Minibatch loss: 0.150, learning rate: 0.000902\n",
      "[(6, 10), (9, 9), (3, 8), (8, 8), (2, 7), (0, 6), (1, 6), (5, 6), (4, 2), (7, 2)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 600), (7, 529), (4, 526), (6, 504), (3, 493), (0, 488), (9, 488), (2, 481), (8, 457), (5, 434)]\n",
      "Validation error: 1.9%\n",
      "Step 2000 (epoch 2.33), 921.4 ms\n",
      "Minibatch loss: 0.049, learning rate: 0.000902\n",
      "[(1, 9), (4, 8), (7, 8), (8, 8), (5, 7), (2, 5), (3, 5), (6, 5), (9, 5), (0, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 567), (7, 560), (4, 557), (2, 499), (6, 494), (3, 490), (0, 478), (9, 473), (8, 455), (5, 427)]\n",
      "Validation error: 1.9%\n",
      "Step 2100 (epoch 2.44), 923.5 ms\n",
      "Minibatch loss: 0.271, learning rate: 0.000902\n",
      "[(4, 13), (0, 10), (1, 8), (9, 8), (6, 6), (8, 6), (5, 5), (3, 3), (7, 3), (2, 2)]\n",
      "Minibatch error: 1.6%\n",
      "[(7, 559), (1, 554), (4, 533), (3, 505), (6, 499), (8, 499), (2, 489), (0, 478), (9, 464), (5, 420)]\n",
      "Validation error: 2.1%\n",
      "Step 2200 (epoch 2.56), 927.4 ms\n",
      "Minibatch loss: 0.049, learning rate: 0.000902\n",
      "[(8, 10), (0, 9), (3, 8), (7, 8), (4, 7), (6, 6), (5, 5), (1, 4), (2, 4), (9, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 554), (7, 541), (4, 527), (3, 515), (6, 489), (2, 484), (9, 484), (0, 470), (8, 469), (5, 467)]\n",
      "Validation error: 2.2%\n",
      "Step 2300 (epoch 2.68), 919.5 ms\n",
      "Minibatch loss: 0.176, learning rate: 0.000902\n",
      "[(4, 8), (5, 8), (0, 7), (6, 7), (8, 7), (1, 6), (2, 6), (9, 6), (7, 5), (3, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(6, 559), (1, 543), (4, 537), (2, 520), (9, 501), (7, 495), (3, 480), (0, 469), (8, 467), (5, 429)]\n",
      "Validation error: 3.5%\n",
      "Step 2400 (epoch 2.79), 929.0 ms\n",
      "Minibatch loss: 0.065, learning rate: 0.000902\n",
      "[(4, 10), (3, 8), (8, 8), (6, 7), (9, 7), (0, 6), (2, 5), (5, 5), (7, 5), (1, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 564), (7, 555), (4, 544), (6, 504), (2, 496), (3, 487), (0, 481), (9, 480), (8, 456), (5, 433)]\n",
      "Validation error: 1.6%\n",
      "Step 2500 (epoch 2.91), 919.2 ms\n",
      "Minibatch loss: 0.097, learning rate: 0.000902\n",
      "[(2, 11), (6, 9), (8, 9), (1, 7), (4, 7), (3, 6), (7, 6), (5, 4), (0, 3), (9, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(7, 561), (1, 548), (4, 537), (6, 509), (3, 504), (2, 491), (9, 487), (0, 478), (8, 449), (5, 436)]\n",
      "Validation error: 2.1%\n",
      "Step 2600 (epoch 3.03), 926.1 ms\n",
      "Minibatch loss: 0.149, learning rate: 0.000857\n",
      "[(0, 11), (2, 10), (3, 7), (1, 6), (4, 6), (5, 5), (7, 5), (8, 5), (9, 5), (6, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 565), (7, 551), (9, 514), (3, 512), (4, 506), (6, 506), (2, 484), (0, 471), (8, 457), (5, 434)]\n",
      "Validation error: 2.2%\n",
      "Step 2700 (epoch 3.14), 917.4 ms\n",
      "Minibatch loss: 0.243, learning rate: 0.000857\n",
      "[(2, 9), (9, 9), (0, 8), (7, 8), (6, 6), (8, 6), (1, 5), (4, 5), (3, 4), (5, 4)]\n",
      "Minibatch error: 4.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 558), (7, 552), (4, 527), (2, 520), (9, 503), (6, 496), (3, 494), (0, 489), (5, 434), (8, 427)]\n",
      "Validation error: 2.2%\n",
      "Step 2800 (epoch 3.26), 924.1 ms\n",
      "Minibatch loss: 0.031, learning rate: 0.000857\n",
      "[(1, 10), (2, 8), (4, 8), (5, 7), (7, 7), (9, 7), (0, 5), (3, 5), (6, 4), (8, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 567), (7, 561), (4, 549), (2, 523), (6, 489), (3, 486), (9, 486), (0, 481), (5, 432), (8, 426)]\n",
      "Validation error: 2.2%\n",
      "Step 2900 (epoch 3.37), 927.3 ms\n",
      "Minibatch loss: 0.142, learning rate: 0.000857\n",
      "[(7, 10), (1, 8), (4, 7), (8, 7), (9, 7), (0, 6), (2, 6), (5, 5), (3, 4), (6, 4)]\n",
      "Minibatch error: 3.1%\n",
      "[(1, 567), (7, 560), (4, 534), (3, 495), (6, 488), (8, 484), (2, 480), (9, 480), (0, 478), (5, 434)]\n",
      "Validation error: 1.4%\n",
      "Step 3000 (epoch 3.49), 916.4 ms\n",
      "Minibatch loss: 0.034, learning rate: 0.000857\n",
      "[(6, 10), (3, 8), (7, 8), (5, 7), (8, 7), (1, 6), (9, 6), (2, 5), (0, 4), (4, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(7, 565), (1, 557), (4, 523), (3, 515), (9, 491), (2, 485), (5, 478), (0, 475), (8, 467), (6, 444)]\n",
      "Validation error: 2.8%\n",
      "Step 3100 (epoch 3.61), 919.5 ms\n",
      "Minibatch loss: 0.327, learning rate: 0.000857\n",
      "[(5, 10), (4, 9), (2, 8), (8, 8), (9, 8), (7, 6), (6, 5), (3, 4), (0, 3), (1, 3)]\n",
      "Minibatch error: 4.7%\n",
      "[(1, 548), (7, 540), (4, 526), (6, 508), (3, 495), (2, 494), (9, 489), (8, 480), (0, 475), (5, 445)]\n",
      "Validation error: 2.1%\n",
      "Step 3200 (epoch 3.72), 895.2 ms\n",
      "Minibatch loss: 0.456, learning rate: 0.000857\n",
      "[(1, 9), (5, 9), (2, 7), (7, 7), (3, 6), (4, 6), (8, 6), (9, 6), (6, 5), (0, 3)]\n",
      "Minibatch error: 3.1%\n",
      "[(1, 556), (7, 533), (6, 528), (9, 511), (4, 506), (8, 484), (3, 480), (2, 472), (0, 470), (5, 460)]\n",
      "Validation error: 3.3%\n",
      "Step 3300 (epoch 3.84), 930.2 ms\n",
      "Minibatch loss: 0.054, learning rate: 0.000857\n",
      "[(6, 9), (8, 9), (1, 8), (2, 7), (4, 7), (5, 6), (0, 5), (7, 5), (9, 5), (3, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 563), (7, 555), (4, 532), (6, 509), (9, 495), (3, 488), (2, 487), (0, 480), (8, 467), (5, 424)]\n",
      "Validation error: 1.5%\n",
      "Step 3400 (epoch 3.96), 922.4 ms\n",
      "Minibatch loss: 0.049, learning rate: 0.000857\n",
      "[(5, 11), (0, 8), (1, 8), (4, 7), (7, 7), (3, 6), (6, 6), (2, 5), (8, 3), (9, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(7, 569), (1, 565), (4, 528), (3, 503), (9, 490), (6, 489), (2, 486), (0, 479), (8, 464), (5, 427)]\n",
      "Validation error: 1.8%\n",
      "Step 3500 (epoch 4.07), 905.6 ms\n",
      "Minibatch loss: 0.164, learning rate: 0.000815\n",
      "[(1, 10), (3, 10), (7, 9), (0, 7), (2, 7), (9, 7), (6, 6), (5, 4), (8, 3), (4, 1)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 558), (4, 533), (7, 525), (2, 516), (3, 514), (6, 496), (8, 490), (9, 480), (0, 468), (5, 420)]\n",
      "Validation error: 2.3%\n",
      "Step 3600 (epoch 4.19), 905.0 ms\n",
      "Minibatch loss: 0.020, learning rate: 0.000815\n",
      "[(0, 9), (1, 8), (2, 7), (4, 7), (6, 7), (9, 7), (3, 5), (5, 5), (7, 5), (8, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 565), (7, 551), (4, 540), (9, 509), (6, 500), (3, 484), (2, 482), (0, 479), (8, 460), (5, 430)]\n",
      "Validation error: 1.4%\n",
      "Step 3700 (epoch 4.31), 906.9 ms\n",
      "Minibatch loss: 0.029, learning rate: 0.000815\n",
      "[(9, 11), (2, 10), (7, 7), (1, 6), (3, 6), (4, 6), (6, 6), (8, 6), (5, 4), (0, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 568), (7, 551), (4, 536), (6, 507), (3, 498), (2, 496), (9, 493), (0, 480), (8, 445), (5, 426)]\n",
      "Validation error: 1.3%\n",
      "Step 3800 (epoch 4.42), 935.9 ms\n",
      "Minibatch loss: 0.102, learning rate: 0.000815\n",
      "[(4, 12), (8, 11), (0, 8), (5, 7), (1, 6), (3, 6), (6, 6), (9, 4), (2, 3), (7, 1)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 566), (7, 563), (4, 539), (6, 495), (2, 492), (9, 489), (3, 487), (0, 482), (8, 465), (5, 422)]\n",
      "Validation error: 1.4%\n",
      "Step 3900 (epoch 4.54), 906.4 ms\n",
      "Minibatch loss: 0.077, learning rate: 0.000815\n",
      "[(5, 8), (6, 8), (7, 8), (8, 8), (2, 7), (9, 7), (3, 6), (1, 5), (0, 4), (4, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 571), (7, 555), (4, 537), (3, 504), (6, 500), (2, 490), (9, 485), (0, 480), (8, 449), (5, 429)]\n",
      "Validation error: 1.3%\n",
      "Step 4000 (epoch 4.65), 944.2 ms\n",
      "Minibatch loss: 0.174, learning rate: 0.000815\n",
      "[(0, 9), (6, 9), (2, 8), (7, 8), (9, 8), (5, 7), (3, 5), (1, 4), (4, 4), (8, 2)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 566), (7, 556), (4, 537), (6, 499), (2, 492), (3, 489), (9, 489), (0, 483), (8, 458), (5, 431)]\n",
      "Validation error: 1.0%\n",
      "Step 4100 (epoch 4.77), 925.2 ms\n",
      "Minibatch loss: 0.168, learning rate: 0.000815\n",
      "[(2, 9), (1, 8), (6, 8), (9, 8), (4, 7), (7, 6), (0, 5), (8, 5), (3, 4), (5, 4)]\n",
      "Minibatch error: 3.1%\n",
      "[(4, 590), (1, 566), (7, 541), (6, 521), (2, 520), (8, 485), (0, 480), (3, 475), (9, 419), (5, 403)]\n",
      "Validation error: 3.4%\n",
      "Step 4200 (epoch 4.89), 910.5 ms\n",
      "Minibatch loss: 0.110, learning rate: 0.000815\n",
      "[(7, 11), (1, 8), (9, 8), (0, 7), (2, 7), (3, 7), (5, 5), (6, 4), (8, 4), (4, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 571), (7, 564), (4, 539), (9, 504), (6, 491), (0, 484), (8, 481), (3, 479), (2, 457), (5, 430)]\n",
      "Validation error: 1.9%\n",
      "Step 4300 (epoch 5.00), 925.5 ms\n",
      "Minibatch loss: 0.125, learning rate: 0.000774\n",
      "[(7, 10), (9, 9), (1, 8), (3, 7), (6, 7), (8, 7), (0, 5), (4, 5), (2, 3), (5, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 565), (7, 549), (4, 508), (9, 504), (6, 503), (2, 495), (0, 487), (3, 480), (8, 464), (5, 445)]\n",
      "Validation error: 1.9%\n",
      "Step 4400 (epoch 5.12), 928.6 ms\n",
      "Minibatch loss: 0.055, learning rate: 0.000774\n",
      "[(0, 8), (3, 8), (4, 8), (5, 8), (6, 8), (9, 8), (1, 6), (8, 4), (2, 3), (7, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 568), (7, 553), (4, 537), (6, 504), (3, 497), (9, 494), (0, 483), (2, 475), (8, 459), (5, 430)]\n",
      "Validation error: 1.1%\n",
      "Step 4500 (epoch 5.24), 913.5 ms\n",
      "Minibatch loss: 0.210, learning rate: 0.000774\n",
      "[(8, 10), (6, 9), (5, 8), (7, 8), (1, 6), (4, 6), (3, 5), (0, 4), (2, 4), (9, 4)]\n",
      "Minibatch error: 3.1%\n",
      "[(4, 590), (1, 579), (7, 554), (6, 503), (9, 503), (2, 475), (3, 470), (0, 450), (8, 441), (5, 435)]\n",
      "Validation error: 2.8%\n",
      "Step 4600 (epoch 5.35), 908.4 ms\n",
      "Minibatch loss: 0.048, learning rate: 0.000774\n",
      "[(3, 10), (4, 8), (6, 8), (1, 7), (2, 7), (8, 6), (5, 5), (9, 5), (0, 4), (7, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 572), (7, 545), (4, 534), (3, 503), (6, 495), (9, 486), (2, 484), (0, 483), (8, 460), (5, 438)]\n",
      "Validation error: 1.1%\n",
      "Step 4700 (epoch 5.47), 927.7 ms\n",
      "Minibatch loss: 0.056, learning rate: 0.000774\n",
      "[(0, 9), (1, 9), (9, 9), (3, 7), (4, 6), (8, 6), (2, 5), (6, 5), (7, 5), (5, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 559), (7, 550), (4, 531), (3, 512), (6, 503), (9, 492), (2, 490), (0, 478), (8, 459), (5, 426)]\n",
      "Validation error: 1.3%\n",
      "Step 4800 (epoch 5.59), 922.1 ms\n",
      "Minibatch loss: 0.029, learning rate: 0.000774\n",
      "[(5, 9), (2, 8), (6, 8), (7, 8), (3, 7), (1, 6), (9, 6), (0, 5), (4, 4), (8, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 564), (7, 542), (4, 527), (6, 507), (9, 502), (3, 491), (2, 485), (0, 476), (8, 470), (5, 436)]\n",
      "Validation error: 1.2%\n",
      "Step 4900 (epoch 5.70), 919.9 ms\n",
      "Minibatch loss: 0.042, learning rate: 0.000774\n",
      "[(0, 9), (8, 8), (1, 7), (3, 7), (4, 7), (6, 7), (9, 6), (7, 5), (2, 4), (5, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(7, 546), (1, 540), (6, 523), (9, 512), (4, 511), (3, 487), (2, 486), (5, 476), (0, 473), (8, 446)]\n",
      "Validation error: 2.4%\n",
      "Step 5000 (epoch 5.82), 933.2 ms\n",
      "Minibatch loss: 0.238, learning rate: 0.000774\n",
      "[(7, 11), (3, 9), (0, 8), (1, 8), (5, 8), (2, 6), (8, 5), (9, 4), (6, 3), (4, 2)]\n",
      "Minibatch error: 3.1%\n",
      "[(1, 561), (7, 555), (4, 528), (6, 495), (9, 495), (2, 489), (3, 488), (0, 481), (8, 463), (5, 445)]\n",
      "Validation error: 1.4%\n",
      "Step 5100 (epoch 5.93), 928.9 ms\n",
      "Minibatch loss: 0.039, learning rate: 0.000774\n",
      "[(1, 11), (0, 8), (3, 7), (4, 7), (5, 7), (7, 6), (9, 6), (6, 5), (2, 4), (8, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 566), (7, 559), (4, 538), (9, 503), (6, 489), (3, 486), (2, 479), (0, 478), (8, 455), (5, 447)]\n",
      "Validation error: 1.5%\n",
      "Step 5200 (epoch 6.05), 921.4 ms\n",
      "Minibatch loss: 0.233, learning rate: 0.000735\n",
      "[(3, 10), (7, 8), (1, 7), (4, 7), (8, 7), (9, 7), (2, 6), (0, 5), (6, 4), (5, 3)]\n",
      "Minibatch error: 3.1%\n",
      "[(1, 571), (7, 559), (4, 537), (6, 496), (2, 485), (8, 484), (3, 482), (0, 480), (9, 477), (5, 429)]\n",
      "Validation error: 1.6%\n",
      "Step 5300 (epoch 6.17), 911.8 ms\n",
      "Minibatch loss: 0.046, learning rate: 0.000735\n",
      "[(7, 11), (6, 8), (1, 7), (4, 7), (5, 7), (8, 7), (2, 5), (3, 5), (0, 4), (9, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 561), (4, 552), (7, 540), (2, 496), (6, 495), (9, 495), (3, 488), (0, 482), (8, 466), (5, 425)]\n",
      "Validation error: 1.5%\n",
      "Step 5400 (epoch 6.28), 932.4 ms\n",
      "Minibatch loss: 0.080, learning rate: 0.000735\n",
      "[(2, 10), (6, 9), (3, 8), (5, 8), (1, 7), (7, 6), (9, 6), (4, 5), (8, 3), (0, 2)]\n",
      "Minibatch error: 1.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 573), (7, 559), (4, 536), (6, 495), (9, 493), (3, 485), (2, 481), (0, 480), (8, 462), (5, 436)]\n",
      "Validation error: 1.1%\n",
      "Step 5500 (epoch 6.40), 939.6 ms\n",
      "Minibatch loss: 0.068, learning rate: 0.000735\n",
      "[(0, 11), (5, 10), (2, 8), (6, 8), (3, 6), (1, 5), (8, 5), (9, 5), (4, 4), (7, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 558), (7, 555), (9, 512), (4, 506), (6, 500), (2, 495), (3, 491), (0, 480), (8, 471), (5, 432)]\n",
      "Validation error: 1.7%\n",
      "Step 5600 (epoch 6.52), 920.8 ms\n",
      "Minibatch loss: 0.014, learning rate: 0.000735\n",
      "[(7, 9), (3, 8), (4, 8), (0, 7), (8, 7), (2, 6), (1, 5), (6, 5), (9, 5), (5, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 566), (4, 555), (7, 552), (6, 500), (2, 489), (3, 488), (0, 479), (9, 476), (8, 465), (5, 430)]\n",
      "Validation error: 1.3%\n",
      "Step 5700 (epoch 6.63), 903.5 ms\n",
      "Minibatch loss: 0.037, learning rate: 0.000735\n",
      "[(7, 12), (0, 11), (4, 7), (1, 6), (3, 6), (2, 5), (6, 5), (8, 5), (5, 4), (9, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 573), (7, 542), (4, 533), (0, 493), (9, 493), (3, 492), (2, 490), (6, 486), (8, 465), (5, 433)]\n",
      "Validation error: 1.2%\n",
      "Step 5800 (epoch 6.75), 920.7 ms\n",
      "Minibatch loss: 0.009, learning rate: 0.000735\n",
      "[(7, 9), (0, 7), (2, 7), (3, 7), (5, 7), (6, 7), (8, 7), (4, 6), (9, 4), (1, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 569), (7, 558), (4, 538), (3, 501), (6, 499), (9, 490), (2, 486), (0, 480), (8, 457), (5, 422)]\n",
      "Validation error: 1.3%\n",
      "Step 5900 (epoch 6.87), 931.0 ms\n",
      "Minibatch loss: 0.022, learning rate: 0.000735\n",
      "[(1, 9), (2, 9), (7, 7), (0, 6), (4, 6), (8, 6), (9, 6), (3, 5), (5, 5), (6, 5)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 567), (7, 559), (4, 553), (2, 487), (3, 487), (9, 487), (6, 486), (0, 478), (8, 464), (5, 432)]\n",
      "Validation error: 1.4%\n",
      "Step 6000 (epoch 6.98), 922.9 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000735\n",
      "[(8, 9), (2, 7), (4, 7), (5, 7), (7, 7), (1, 6), (3, 6), (0, 5), (6, 5), (9, 5)]\n",
      "Minibatch error: 0.0%\n",
      "[(7, 581), (1, 570), (4, 511), (9, 506), (3, 495), (6, 488), (0, 484), (2, 480), (8, 457), (5, 428)]\n",
      "Validation error: 1.9%\n",
      "Step 6100 (epoch 7.10), 890.1 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000698\n",
      "[(1, 9), (3, 9), (4, 8), (8, 8), (5, 7), (9, 7), (0, 5), (6, 5), (7, 5), (2, 1)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 571), (7, 560), (4, 531), (6, 501), (3, 489), (9, 486), (2, 485), (0, 481), (8, 460), (5, 436)]\n",
      "Validation error: 1.0%\n",
      "Step 6200 (epoch 7.21), 949.7 ms\n",
      "Minibatch loss: 0.062, learning rate: 0.000698\n",
      "[(3, 12), (7, 8), (1, 7), (4, 7), (6, 7), (8, 6), (2, 5), (9, 5), (5, 4), (0, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 566), (7, 547), (4, 539), (6, 510), (3, 492), (2, 490), (9, 483), (0, 482), (8, 463), (5, 428)]\n",
      "Validation error: 1.1%\n",
      "Step 6300 (epoch 7.33), 918.9 ms\n",
      "Minibatch loss: 0.007, learning rate: 0.000698\n",
      "[(6, 10), (7, 9), (2, 7), (4, 7), (5, 7), (3, 6), (8, 6), (1, 5), (9, 4), (0, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 562), (7, 548), (4, 539), (6, 500), (9, 492), (2, 490), (3, 485), (0, 481), (8, 464), (5, 439)]\n",
      "Validation error: 0.9%\n",
      "Step 6400 (epoch 7.45), 897.8 ms\n",
      "Minibatch loss: 0.124, learning rate: 0.000698\n",
      "[(2, 11), (3, 10), (0, 8), (9, 8), (1, 6), (4, 5), (8, 5), (5, 4), (6, 4), (7, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 563), (7, 561), (4, 545), (6, 503), (3, 493), (9, 482), (0, 480), (2, 479), (8, 462), (5, 432)]\n",
      "Validation error: 1.2%\n",
      "Step 6500 (epoch 7.56), 910.2 ms\n",
      "Minibatch loss: 0.015, learning rate: 0.000698\n",
      "[(9, 12), (5, 10), (1, 8), (2, 7), (0, 5), (3, 5), (4, 5), (8, 5), (7, 4), (6, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 567), (7, 553), (4, 529), (6, 497), (9, 495), (3, 494), (0, 481), (2, 479), (8, 459), (5, 446)]\n",
      "Validation error: 1.2%\n",
      "Step 6600 (epoch 7.68), 912.1 ms\n",
      "Minibatch loss: 0.203, learning rate: 0.000698\n",
      "[(1, 11), (9, 11), (0, 7), (3, 7), (2, 6), (8, 6), (5, 5), (6, 4), (7, 4), (4, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 564), (7, 530), (4, 517), (9, 515), (6, 504), (3, 493), (2, 485), (0, 484), (8, 460), (5, 448)]\n",
      "Validation error: 2.0%\n",
      "Step 6700 (epoch 7.80), 925.3 ms\n",
      "Minibatch loss: 0.020, learning rate: 0.000698\n",
      "[(3, 10), (0, 9), (8, 9), (4, 7), (6, 7), (1, 6), (2, 5), (5, 4), (9, 4), (7, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 563), (7, 547), (4, 539), (6, 501), (9, 493), (3, 492), (2, 490), (0, 480), (8, 469), (5, 426)]\n",
      "Validation error: 0.8%\n",
      "Step 6800 (epoch 7.91), 935.7 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000698\n",
      "[(0, 9), (2, 8), (4, 8), (3, 7), (7, 7), (8, 7), (9, 6), (5, 5), (1, 4), (6, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 558), (7, 557), (4, 550), (6, 499), (9, 490), (2, 489), (3, 487), (0, 479), (8, 470), (5, 421)]\n",
      "Validation error: 1.3%\n",
      "Step 6900 (epoch 8.03), 915.6 ms\n",
      "Minibatch loss: 0.053, learning rate: 0.000663\n",
      "[(5, 9), (8, 9), (0, 8), (1, 8), (3, 7), (2, 6), (4, 5), (7, 5), (9, 5), (6, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 568), (7, 558), (4, 527), (3, 501), (6, 498), (2, 491), (9, 487), (0, 479), (8, 458), (5, 433)]\n",
      "Validation error: 1.2%\n",
      "Step 7000 (epoch 8.15), 912.3 ms\n",
      "Minibatch loss: 0.047, learning rate: 0.000663\n",
      "[(7, 11), (3, 8), (1, 7), (2, 7), (4, 6), (9, 6), (0, 5), (5, 5), (8, 5), (6, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 568), (7, 559), (4, 539), (3, 495), (6, 492), (2, 488), (0, 485), (9, 485), (8, 459), (5, 430)]\n",
      "Validation error: 1.2%\n",
      "Step 7100 (epoch 8.26), 924.4 ms\n",
      "Minibatch loss: 0.039, learning rate: 0.000663\n",
      "[(6, 9), (4, 8), (5, 8), (9, 8), (1, 7), (0, 6), (3, 6), (8, 5), (2, 4), (7, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 567), (7, 549), (4, 541), (6, 500), (9, 499), (2, 497), (0, 478), (3, 476), (8, 462), (5, 431)]\n",
      "Validation error: 1.2%\n",
      "Step 7200 (epoch 8.38), 924.9 ms\n",
      "Minibatch loss: 0.119, learning rate: 0.000663\n",
      "[(2, 11), (9, 9), (0, 8), (5, 8), (6, 8), (7, 6), (4, 5), (8, 4), (1, 3), (3, 2)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 568), (7, 551), (4, 542), (6, 494), (3, 493), (2, 488), (0, 481), (9, 481), (8, 472), (5, 430)]\n",
      "Validation error: 1.1%\n",
      "Step 7300 (epoch 8.49), 917.7 ms\n",
      "Minibatch loss: 0.125, learning rate: 0.000663\n",
      "[(8, 10), (9, 10), (5, 8), (1, 7), (6, 7), (2, 5), (3, 5), (4, 5), (7, 4), (0, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 565), (7, 559), (4, 537), (6, 499), (3, 489), (9, 485), (2, 482), (8, 470), (0, 462), (5, 452)]\n",
      "Validation error: 1.3%\n",
      "Step 7400 (epoch 8.61), 911.7 ms\n",
      "Minibatch loss: 0.007, learning rate: 0.000663\n",
      "[(2, 10), (3, 8), (1, 7), (6, 7), (8, 7), (9, 7), (0, 5), (4, 5), (5, 5), (7, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 566), (7, 547), (4, 535), (6, 495), (2, 494), (9, 494), (3, 485), (0, 478), (8, 462), (5, 444)]\n",
      "Validation error: 0.9%\n",
      "Step 7500 (epoch 8.73), 915.3 ms\n",
      "Minibatch loss: 0.022, learning rate: 0.000663\n",
      "[(7, 10), (1, 8), (5, 8), (6, 8), (0, 7), (4, 6), (9, 5), (2, 4), (3, 4), (8, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 559), (7, 555), (4, 536), (3, 497), (6, 495), (9, 491), (2, 486), (0, 481), (8, 468), (5, 432)]\n",
      "Validation error: 0.9%\n",
      "Step 7600 (epoch 8.84), 910.8 ms\n",
      "Minibatch loss: 0.134, learning rate: 0.000663\n",
      "[(7, 9), (4, 8), (9, 8), (3, 7), (8, 7), (2, 6), (5, 6), (1, 5), (6, 5), (0, 3)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 567), (7, 552), (4, 527), (6, 504), (3, 496), (9, 496), (0, 482), (2, 481), (8, 461), (5, 434)]\n",
      "Validation error: 0.8%\n",
      "Step 7700 (epoch 8.96), 939.2 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000663\n",
      "[(9, 10), (5, 8), (0, 7), (1, 7), (3, 7), (2, 5), (4, 5), (6, 5), (7, 5), (8, 5)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 571), (7, 546), (4, 531), (9, 502), (6, 495), (0, 488), (3, 485), (2, 484), (8, 459), (5, 439)]\n",
      "Validation error: 1.0%\n",
      "Step 7800 (epoch 9.08), 923.9 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000630\n",
      "[(8, 9), (2, 8), (6, 8), (9, 8), (0, 6), (3, 6), (5, 6), (1, 5), (7, 5), (4, 3)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 569), (7, 538), (4, 536), (2, 503), (6, 497), (3, 490), (9, 484), (0, 480), (8, 472), (5, 431)]\n",
      "Validation error: 1.2%\n",
      "Step 7900 (epoch 9.19), 925.7 ms\n",
      "Minibatch loss: 0.014, learning rate: 0.000630\n",
      "[(1, 11), (2, 8), (3, 8), (7, 8), (0, 7), (8, 7), (4, 6), (5, 4), (6, 3), (9, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 565), (7, 555), (4, 537), (6, 505), (9, 491), (2, 485), (3, 482), (0, 477), (8, 462), (5, 441)]\n",
      "Validation error: 1.0%\n",
      "Step 8000 (epoch 9.31), 932.3 ms\n",
      "Minibatch loss: 0.192, learning rate: 0.000630\n",
      "[(0, 10), (2, 8), (1, 7), (4, 7), (6, 7), (3, 6), (7, 6), (8, 5), (5, 4), (9, 4)]\n",
      "Minibatch error: 1.6%\n",
      "[(1, 568), (7, 547), (4, 537), (6, 504), (9, 497), (2, 489), (3, 485), (0, 481), (8, 461), (5, 431)]\n",
      "Validation error: 0.8%\n",
      "Step 8100 (epoch 9.43), 921.5 ms\n",
      "Minibatch loss: 0.084, learning rate: 0.000630\n",
      "[(2, 9), (9, 9), (5, 8), (7, 7), (4, 6), (6, 6), (8, 6), (3, 5), (0, 4), (1, 4)]\n",
      "Minibatch error: 0.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 561), (7, 552), (4, 525), (9, 511), (3, 503), (6, 502), (0, 480), (2, 474), (8, 459), (5, 433)]\n",
      "Validation error: 1.4%\n",
      "Step 8200 (epoch 9.54), 908.6 ms\n",
      "Minibatch loss: 0.030, learning rate: 0.000630\n",
      "[(1, 11), (3, 8), (6, 8), (4, 7), (0, 6), (2, 6), (5, 6), (7, 4), (8, 4), (9, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 571), (4, 549), (7, 549), (3, 518), (6, 493), (9, 491), (0, 478), (2, 468), (8, 443), (5, 440)]\n",
      "Validation error: 1.7%\n",
      "Step 8300 (epoch 9.66), 913.5 ms\n",
      "Minibatch loss: 0.076, learning rate: 0.000630\n",
      "[(1, 12), (6, 10), (0, 8), (9, 8), (2, 6), (4, 6), (3, 5), (5, 5), (7, 2), (8, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 565), (7, 536), (4, 531), (9, 509), (6, 504), (3, 491), (0, 486), (2, 483), (8, 467), (5, 428)]\n",
      "Validation error: 1.2%\n",
      "Step 8400 (epoch 9.77), 908.7 ms\n",
      "Minibatch loss: 0.041, learning rate: 0.000630\n",
      "[(0, 10), (1, 9), (2, 8), (4, 7), (9, 7), (5, 5), (7, 5), (8, 5), (3, 4), (6, 4)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 564), (4, 557), (7, 538), (6, 502), (3, 496), (2, 491), (9, 484), (0, 480), (8, 463), (5, 425)]\n",
      "Validation error: 1.3%\n",
      "Step 8500 (epoch 9.89), 916.1 ms\n",
      "Minibatch loss: 0.031, learning rate: 0.000630\n",
      "[(8, 10), (1, 8), (0, 7), (5, 7), (6, 7), (9, 7), (3, 6), (4, 6), (7, 4), (2, 2)]\n",
      "Minibatch error: 0.0%\n",
      "[(1, 564), (7, 553), (4, 533), (9, 503), (6, 497), (3, 485), (0, 481), (2, 481), (8, 475), (5, 428)]\n",
      "Validation error: 1.1%\n",
      "[(1, 1154), (2, 1025), (7, 1024), (3, 1020), (9, 1010), (4, 980), (0, 979), (8, 971), (6, 948), (5, 889)]\n",
      "Test error: 0.9%\n"
     ]
    }
   ],
   "source": [
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    1e-3,                # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "    train_prediction, loss = apply(train_data_node, training=True)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
    "                                                   global_step=batch)\n",
    "\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    eval_prediction, _ = apply(eval_data, training=False)\n",
    "\n",
    "  # Small utility function to evaluate a dataset by feeding batches of data to\n",
    "  # {eval_data} and pulling the results from {eval_predictions}.\n",
    "  # Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "      raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "      end = begin + EVAL_BATCH_SIZE\n",
    "      if end <= size:\n",
    "        predictions[begin:end, :] = sess.run(\n",
    "            eval_prediction,\n",
    "            feed_dict={eval_data: data[begin:end, ...]})\n",
    "      else:\n",
    "        batch_predictions = sess.run(\n",
    "            eval_prediction,\n",
    "            feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "        predictions[begin:, :] = batch_predictions[begin - size:, :]\n",
    "    return predictions\n",
    "\n",
    "  # Create a local session to run the training.\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE):\n",
    "      # Compute the offset of the current minibatch in the data.\n",
    "      # Note that we could use better randomization across epochs.\n",
    "      offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "      batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "      batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "      # This dictionary maps the batch data (as a numpy array) to the\n",
    "      # node in the graph it should be fed to.\n",
    "      feed_dict = {train_data_node: batch_data,\n",
    "                   train_labels_node: batch_labels}\n",
    "      # Run the optimizer to update weights.\n",
    "      sess.run(optimizer, feed_dict=feed_dict)\n",
    "      # print some extra information once reach the evaluation frequency\n",
    "      if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        l, lr, predictions = sess.run([loss, learning_rate, train_prediction],\n",
    "                                      feed_dict=feed_dict)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        print('Step %d (epoch %.2f), %.1f ms' %\n",
    "              (step, float(step) * BATCH_SIZE / train_size,\n",
    "               1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "        print('Minibatch loss: %.3f, learning rate: %.6f' % (l, lr))\n",
    "        print('Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))\n",
    "        print('Validation error: %.1f%%' % error_rate(\n",
    "            eval_in_batches(validation_data, sess), validation_labels))\n",
    "        sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "    print('Test error: %.1f%%' % test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
