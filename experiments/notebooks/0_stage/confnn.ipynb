{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Work in progress, not a complete example.\n",
    "\n",
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST example (data downloading etc.) is based on Google's https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "# See LICENSE for details.\n",
    "\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "WORK_DIRECTORY = 'data'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100  # Number of steps between evaluations.\n",
    "\n",
    "EMBEDDING_SIZE = 10\n",
    "NUM_INTERNAL_CONVS = 5\n",
    "NUM_UNROLL_STEPS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "def maybe_download(filename):\n",
    "  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "  if not tf.gfile.Exists(WORK_DIRECTORY):\n",
    "    tf.gfile.MakeDirs(WORK_DIRECTORY)\n",
    "  filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "  if not tf.gfile.Exists(filepath):\n",
    "    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "    with tf.gfile.GFile(filepath) as f:\n",
    "      size = f.size()\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "  return filepath\n",
    "\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "\n",
    "  Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "  \"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n",
    "  return labels\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def error_rate_single(predictions, labels):\n",
    "  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\n",
    "  argmax = numpy.argmax(predictions, 1)\n",
    "  #print(Counter(argmax).most_common())\n",
    "  return 100.0 - (\n",
    "      100.0 *\n",
    "      numpy.sum(argmax == labels) /\n",
    "      predictions.shape[0])\n",
    "\n",
    "\n",
    "def error_rate(predictions_all_steps, labels):\n",
    "  return [error_rate_single(predictions_all_steps[i], labels) for i in range(NUM_UNROLL_STEPS)]\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "# Generate a validation set.\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, ...]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "train_size = train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(input_images, training):\n",
    "    x = input_images\n",
    "    x = tf.layers.conv2d(x, filters=16, kernel_size=[5,5], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, momentum=0.9, scale=False, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, filters=32, kernel_size=[3,3], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, momentum=0.9, scale=False, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=[3,3], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, momentum=0.9, scale=False, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=[3,3], strides=1,\n",
    "                         padding=\"VALID\")\n",
    "    x = tf.layers.batch_normalization(x, momentum=0.9, fused=True, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "def model_step(input_images, prior, batch_size):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    prior_embeddings = tf.get_variable(\"prior_embeddings\",\n",
    "                                        shape=[NUM_LABELS, EMBEDDING_SIZE - 1],\n",
    "                                        initializer=tf.random_uniform_initializer(\n",
    "                                            minval=-1.0/numpy.sqrt(NUM_LABELS), maxval=1.0/numpy.sqrt(NUM_LABELS)))\n",
    "    raw_embedding_features = tf.matmul(prior, prior_embeddings)\n",
    "    prior_entropy = - tf.reduce_sum(prior * tf.log(1e-4 + prior), axis=-1, keep_dims=True)\n",
    "    embedding_features = tf.concat([raw_embedding_features, prior_entropy], axis=-1)\n",
    "    for i in range(4):\n",
    "        gates = tf.layers.dense(\n",
    "            embedding_features, EMBEDDING_SIZE, activation=tf.nn.sigmoid)\n",
    "        embedding_features = gates * (embedding_features + tf.layers.dense(\n",
    "            embedding_features, EMBEDDING_SIZE, use_bias=False, activation=tf.nn.relu))\n",
    "    \n",
    "    def get_dynamic_weights(weights_shape):\n",
    "        num_weights = numpy.prod(weights_shape[1:])\n",
    "        dynamic_weights_flat = tf.layers.dense(embedding_features, num_weights)\n",
    "        dynamic_weights = tf.reshape(dynamic_weights_flat, weights_shape)\n",
    "        dynamic_weights.set_shape(weights_shape)\n",
    "        return dynamic_weights\n",
    "    \n",
    "    conv1_weights = get_dynamic_weights([batch_size, 1, 1, 128, EMBEDDING_SIZE])\n",
    "    conv2_weights = [get_dynamic_weights([batch_size, 2, 2, EMBEDDING_SIZE, EMBEDDING_SIZE])\n",
    "                     for _ in range(NUM_INTERNAL_CONVS)]\n",
    "    conv3_weights = get_dynamic_weights([batch_size, 1, 1, EMBEDDING_SIZE, NUM_LABELS])\n",
    "    conv3_biases = get_dynamic_weights([batch_size, NUM_LABELS])\n",
    "    \n",
    "    logits_lst, posteriors_lst = [], []\n",
    "    for elm in range(batch_size):\n",
    "        conv = tf.nn.conv2d([input_images[elm]],\n",
    "                            conv1_weights[elm],\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding='VALID')\n",
    "        relu = tf.nn.relu(conv)\n",
    "        for i in range(NUM_INTERNAL_CONVS):\n",
    "            conv = tf.nn.conv2d(relu,\n",
    "                            conv2_weights[i][elm],\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding='SAME')\n",
    "            relu = tf.nn.relu(conv) + relu\n",
    "        conv = tf.nn.conv2d(relu,\n",
    "                            conv3_weights[elm],\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding='VALID')\n",
    "        conv_shape = conv.get_shape()\n",
    "        logits = tf.nn.avg_pool(conv, ksize=[1, conv_shape[1], conv_shape[2], 1],\n",
    "                                strides=[1, 1, 1, 1], padding=\"VALID\") + conv3_biases[elm]\n",
    "        logits = tf.squeeze(logits, axis=[1, 2])\n",
    "        posteriors = tf.nn.softmax(logits)\n",
    "        logits_lst.append(logits)\n",
    "        posteriors_lst.append(posteriors)\n",
    "    return tf.concat(logits_lst, axis=0), tf.concat(posteriors_lst, axis=0)\n",
    "\n",
    "def apply(input_images, training):\n",
    "    results = []\n",
    "    loss = 0.0\n",
    "    conv_features = feature_extractor(input_images, training=training)\n",
    "    batch_size = conv_features.get_shape()[0]  # HyperNet operates on single images only\n",
    "    priors = numpy.array([[1/NUM_LABELS for _ in range(NUM_LABELS)] for _ in range(batch_size)],\n",
    "                         dtype=numpy.float32)\n",
    "    for step in range(NUM_UNROLL_STEPS):\n",
    "        logits, posteriors = model_step(conv_features, priors, batch_size)\n",
    "        priors = posteriors\n",
    "        results.append((logits, posteriors))\n",
    "        loss += tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=train_labels_node, logits=logits))\n",
    "    return tf.stack([logits for (logits, _) in results]), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Step 0 (epoch 0.00), 333.4 ms\n",
      "Minibatch loss: 11.530, learning rate: 0.001000\n",
      "Minibatch error: [92.1875, 89.0625, 92.1875, 89.0625, 90.625]\n",
      "Validation error: [90.14, 90.1, 90.14, 89.98, 89.3]\n",
      "Step 100 (epoch 0.12), 1127.4 ms\n",
      "Minibatch loss: 5.007, learning rate: 0.001000\n",
      "Minibatch error: [46.875, 18.75, 15.625, 28.125, 35.9375]\n",
      "Validation error: [58.26, 36.16, 32.31999999999999, 45.12, 37.22]\n",
      "Step 200 (epoch 0.23), 1091.5 ms\n",
      "Minibatch loss: 3.772, learning rate: 0.001000\n",
      "Minibatch error: [48.4375, 20.3125, 14.0625, 20.3125, 14.0625]\n",
      "Validation error: [42.24, 20.560000000000002, 22.299999999999997, 22.519999999999996, 18.78]\n",
      "Step 300 (epoch 0.35), 1092.6 ms\n",
      "Minibatch loss: 2.912, learning rate: 0.001000\n",
      "Minibatch error: [26.5625, 17.1875, 17.1875, 9.375, 10.9375]\n",
      "Validation error: [24.5, 22.900000000000006, 17.0, 18.72, 18.980000000000004]\n",
      "Step 400 (epoch 0.47), 1092.0 ms\n",
      "Minibatch loss: 3.260, learning rate: 0.001000\n",
      "Minibatch error: [25.0, 17.1875, 20.3125, 18.75, 20.3125]\n",
      "Validation error: [30.439999999999998, 24.040000000000006, 23.340000000000003, 26.680000000000007, 28.180000000000007]\n",
      "Step 500 (epoch 0.58), 1094.9 ms\n",
      "Minibatch loss: 2.343, learning rate: 0.001000\n",
      "Minibatch error: [12.5, 9.375, 7.8125, 9.375, 9.375]\n",
      "Validation error: [11.900000000000006, 10.400000000000006, 9.680000000000007, 11.319999999999993, 10.200000000000003]\n",
      "Step 600 (epoch 0.70), 1093.9 ms\n",
      "Minibatch loss: 1.666, learning rate: 0.001000\n",
      "Minibatch error: [9.375, 9.375, 9.375, 10.9375, 9.375]\n",
      "Validation error: [12.060000000000002, 11.659999999999997, 11.319999999999993, 11.5, 13.060000000000002]\n",
      "Step 700 (epoch 0.81), 1102.0 ms\n",
      "Minibatch loss: 1.138, learning rate: 0.001000\n",
      "Minibatch error: [14.0625, 4.6875, 4.6875, 4.6875, 4.6875]\n",
      "Validation error: [12.099999999999994, 7.659999999999997, 7.939999999999998, 8.099999999999994, 7.519999999999996]\n",
      "Step 800 (epoch 0.93), 1101.9 ms\n",
      "Minibatch loss: 1.254, learning rate: 0.001000\n",
      "Minibatch error: [10.9375, 7.8125, 6.25, 6.25, 6.25]\n",
      "Validation error: [10.840000000000003, 5.859999999999999, 6.680000000000007, 6.319999999999993, 6.640000000000001]\n",
      "Step 900 (epoch 1.05), 1101.8 ms\n",
      "Minibatch loss: 0.997, learning rate: 0.000950\n",
      "Minibatch error: [7.8125, 3.125, 3.125, 3.125, 3.125]\n",
      "Validation error: [12.780000000000001, 11.36, 9.5, 10.159999999999997, 9.64]\n",
      "Step 1000 (epoch 1.16), 1094.7 ms\n",
      "Minibatch loss: 1.220, learning rate: 0.000950\n",
      "Minibatch error: [10.9375, 6.25, 7.8125, 7.8125, 7.8125]\n",
      "Validation error: [9.459999999999994, 8.700000000000003, 7.900000000000006, 7.0, 7.099999999999994]\n",
      "Step 1100 (epoch 1.28), 1094.8 ms\n",
      "Minibatch loss: 0.564, learning rate: 0.000950\n",
      "Minibatch error: [4.6875, 3.125, 3.125, 1.5625, 1.5625]\n",
      "Validation error: [21.239999999999995, 11.36, 9.319999999999993, 8.459999999999994, 7.819999999999993]\n",
      "Step 1200 (epoch 1.40), 1093.0 ms\n",
      "Minibatch loss: 0.427, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 1.5625, 1.5625]\n",
      "Validation error: [6.040000000000006, 4.799999999999997, 4.640000000000001, 4.359999999999999, 4.319999999999993]\n",
      "Step 1300 (epoch 1.51), 1088.1 ms\n",
      "Minibatch loss: 0.752, learning rate: 0.000950\n",
      "Minibatch error: [4.6875, 4.6875, 1.5625, 3.125, 3.125]\n",
      "Validation error: [8.459999999999994, 6.5, 5.6200000000000045, 5.400000000000006, 4.959999999999994]\n",
      "Step 1400 (epoch 1.63), 1093.6 ms\n",
      "Minibatch loss: 1.005, learning rate: 0.000950\n",
      "Minibatch error: [14.0625, 3.125, 3.125, 3.125, 3.125]\n",
      "Validation error: [6.739999999999995, 5.3799999999999955, 5.260000000000005, 5.180000000000007, 4.200000000000003]\n",
      "Step 1500 (epoch 1.75), 1092.6 ms\n",
      "Minibatch loss: 1.345, learning rate: 0.000950\n",
      "Minibatch error: [9.375, 7.8125, 6.25, 6.25, 6.25]\n",
      "Validation error: [5.0, 4.519999999999996, 4.780000000000001, 3.6400000000000006, 3.1400000000000006]\n",
      "Step 1600 (epoch 1.86), 1089.0 ms\n",
      "Minibatch loss: 0.537, learning rate: 0.000950\n",
      "Minibatch error: [3.125, 4.6875, 3.125, 3.125, 3.125]\n",
      "Validation error: [4.1200000000000045, 3.239999999999995, 3.3799999999999955, 3.3599999999999994, 3.0999999999999943]\n",
      "Step 1700 (epoch 1.98), 1098.8 ms\n",
      "Minibatch loss: 0.163, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [6.700000000000003, 4.8799999999999955, 4.3799999999999955, 3.8799999999999955, 3.3400000000000034]\n",
      "Step 1800 (epoch 2.09), 1096.2 ms\n",
      "Minibatch loss: 0.253, learning rate: 0.000902\n",
      "Minibatch error: [3.125, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [7.319999999999993, 4.579999999999998, 4.280000000000001, 3.680000000000007, 3.680000000000007]\n",
      "Step 1900 (epoch 2.21), 1097.0 ms\n",
      "Minibatch loss: 0.454, learning rate: 0.000902\n",
      "Minibatch error: [4.6875, 4.6875, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [4.459999999999994, 3.0600000000000023, 3.260000000000005, 3.1599999999999966, 3.480000000000004]\n",
      "Step 2000 (epoch 2.33), 1092.9 ms\n",
      "Minibatch loss: 0.205, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [5.280000000000001, 4.840000000000003, 4.840000000000003, 4.459999999999994, 4.260000000000005]\n",
      "Step 2100 (epoch 2.44), 1091.6 ms\n",
      "Minibatch loss: 0.706, learning rate: 0.000902\n",
      "Minibatch error: [1.5625, 6.25, 3.125, 4.6875, 3.125]\n",
      "Validation error: [3.9399999999999977, 3.5600000000000023, 3.4399999999999977, 3.239999999999995, 3.0]\n",
      "Step 2200 (epoch 2.56), 1094.0 ms\n",
      "Minibatch loss: 0.351, learning rate: 0.000902\n",
      "Minibatch error: [6.25, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [3.739999999999995, 3.0400000000000063, 2.799999999999997, 2.680000000000007, 2.4599999999999937]\n",
      "Step 2300 (epoch 2.68), 1092.4 ms\n",
      "Minibatch loss: 0.498, learning rate: 0.000902\n",
      "Minibatch error: [6.25, 1.5625, 3.125, 1.5625, 3.125]\n",
      "Validation error: [4.659999999999997, 3.4399999999999977, 3.299999999999997, 2.980000000000004, 2.780000000000001]\n",
      "Step 2400 (epoch 2.79), 1093.1 ms\n",
      "Minibatch loss: 0.124, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [4.299999999999997, 3.3599999999999994, 4.099999999999994, 3.819999999999993, 3.5]\n",
      "Step 2500 (epoch 2.91), 1093.8 ms\n",
      "Minibatch loss: 0.145, learning rate: 0.000902\n",
      "Minibatch error: [3.125, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [4.280000000000001, 3.799999999999997, 4.239999999999995, 3.8799999999999955, 4.040000000000006]\n",
      "Step 2600 (epoch 3.03), 1086.8 ms\n",
      "Minibatch loss: 0.207, learning rate: 0.000857\n",
      "Minibatch error: [1.5625, 0.0, 1.5625, 0.0, 0.0]\n",
      "Validation error: [4.299999999999997, 4.5, 4.140000000000001, 3.680000000000007, 2.719999999999999]\n",
      "Step 2700 (epoch 3.14), 1093.1 ms\n",
      "Minibatch loss: 2.660, learning rate: 0.000857\n",
      "Minibatch error: [34.375, 14.0625, 10.9375, 10.9375, 12.5]\n",
      "Validation error: [35.44, 20.799999999999997, 9.019999999999996, 8.019999999999996, 7.659999999999997]\n",
      "Step 2800 (epoch 3.26), 1095.5 ms\n",
      "Minibatch loss: 0.356, learning rate: 0.000857\n",
      "Minibatch error: [1.5625, 0.0, 1.5625, 1.5625, 3.125]\n",
      "Validation error: [3.760000000000005, 2.819999999999993, 2.4599999999999937, 2.4399999999999977, 2.180000000000007]\n",
      "Step 2900 (epoch 3.37), 1090.8 ms\n",
      "Minibatch loss: 0.592, learning rate: 0.000857\n",
      "Minibatch error: [4.6875, 4.6875, 4.6875, 3.125, 1.5625]\n",
      "Validation error: [3.4399999999999977, 2.9599999999999937, 2.680000000000007, 2.4200000000000017, 2.1599999999999966]\n",
      "Step 3000 (epoch 3.49), 1092.9 ms\n",
      "Minibatch loss: 1.058, learning rate: 0.000857\n",
      "Minibatch error: [6.25, 1.5625, 3.125, 3.125, 4.6875]\n",
      "Validation error: [5.819999999999993, 4.8799999999999955, 4.200000000000003, 5.260000000000005, 5.180000000000007]\n",
      "Step 3100 (epoch 3.61), 1093.9 ms\n",
      "Minibatch loss: 0.764, learning rate: 0.000857\n",
      "Minibatch error: [6.25, 3.125, 3.125, 4.6875, 4.6875]\n",
      "Validation error: [3.980000000000004, 3.4399999999999977, 3.180000000000007, 3.0, 2.739999999999995]\n",
      "Step 3200 (epoch 3.72), 1091.0 ms\n",
      "Minibatch loss: 0.406, learning rate: 0.000857\n",
      "Minibatch error: [3.125, 0.0, 3.125, 4.6875, 1.5625]\n",
      "Validation error: [3.200000000000003, 3.0, 2.5400000000000063, 2.480000000000004, 2.180000000000007]\n",
      "Step 3300 (epoch 3.84), 1092.4 ms\n",
      "Minibatch loss: 0.237, learning rate: 0.000857\n",
      "Minibatch error: [3.125, 1.5625, 3.125, 1.5625, 1.5625]\n",
      "Validation error: [4.599999999999994, 4.060000000000002, 3.180000000000007, 3.1400000000000006, 2.680000000000007]\n",
      "Step 3400 (epoch 3.96), 1089.9 ms\n",
      "Minibatch loss: 0.366, learning rate: 0.000857\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: [3.980000000000004, 2.799999999999997, 2.8599999999999994, 2.739999999999995, 2.5799999999999983]\n",
      "Step 3500 (epoch 4.07), 1093.9 ms\n",
      "Minibatch loss: 0.394, learning rate: 0.000815\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 3.125]\n",
      "Validation error: [6.400000000000006, 5.340000000000003, 4.859999999999999, 3.6599999999999966, 3.819999999999993]\n",
      "Step 3600 (epoch 4.19), 1096.7 ms\n",
      "Minibatch loss: 0.038, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [3.180000000000007, 2.4399999999999977, 2.4200000000000017, 2.3799999999999955, 2.0400000000000063]\n",
      "Step 3700 (epoch 4.31), 1098.4 ms\n",
      "Minibatch loss: 0.069, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [3.019999999999996, 2.4000000000000057, 2.5, 2.0400000000000063, 2.180000000000007]\n",
      "Step 3800 (epoch 4.42), 1093.7 ms\n",
      "Minibatch loss: 0.452, learning rate: 0.000815\n",
      "Minibatch error: [4.6875, 4.6875, 1.5625, 1.5625, 3.125]\n",
      "Validation error: [2.9200000000000017, 3.1400000000000006, 2.5, 2.3799999999999955, 2.280000000000001]\n",
      "Step 3900 (epoch 4.54), 1092.7 ms\n",
      "Minibatch loss: 0.356, learning rate: 0.000815\n",
      "Minibatch error: [3.125, 4.6875, 1.5625, 1.5625, 0.0]\n",
      "Validation error: [2.299999999999997, 1.7999999999999972, 1.7800000000000011, 1.6800000000000068, 1.6200000000000045]\n",
      "Step 4000 (epoch 4.65), 1090.8 ms\n",
      "Minibatch loss: 0.790, learning rate: 0.000815\n",
      "Minibatch error: [3.125, 4.6875, 3.125, 3.125, 3.125]\n",
      "Validation error: [2.3599999999999994, 2.319999999999993, 2.0400000000000063, 2.0600000000000023, 2.0999999999999943]\n",
      "Step 4100 (epoch 4.77), 1090.9 ms\n",
      "Minibatch loss: 0.632, learning rate: 0.000815\n",
      "Minibatch error: [3.125, 3.125, 3.125, 3.125, 3.125]\n",
      "Validation error: [3.9599999999999937, 2.680000000000007, 3.1200000000000045, 2.6599999999999966, 2.719999999999999]\n",
      "Step 4200 (epoch 4.89), 1097.9 ms\n",
      "Minibatch loss: 0.490, learning rate: 0.000815\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [2.8599999999999994, 1.9399999999999977, 2.0400000000000063, 1.8599999999999994, 1.7199999999999989]\n",
      "Step 4300 (epoch 5.00), 1099.6 ms\n",
      "Minibatch loss: 0.260, learning rate: 0.000774\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [2.799999999999997, 2.3400000000000034, 1.7399999999999949, 1.6400000000000006, 1.6599999999999966]\n",
      "Step 4400 (epoch 5.12), 1091.0 ms\n",
      "Minibatch loss: 0.313, learning rate: 0.000774\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 3.125, 3.125]\n",
      "Validation error: [6.280000000000001, 3.239999999999995, 2.700000000000003, 3.019999999999996, 2.9399999999999977]\n",
      "Step 4500 (epoch 5.24), 1097.3 ms\n",
      "Minibatch loss: 0.555, learning rate: 0.000774\n",
      "Minibatch error: [6.25, 4.6875, 4.6875, 4.6875, 3.125]\n",
      "Validation error: [3.9599999999999937, 2.8799999999999955, 2.6200000000000045, 2.5, 2.480000000000004]\n",
      "Step 4700 (epoch 5.47), 1097.0 ms\n",
      "Minibatch loss: 0.076, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.9599999999999937, 2.6599999999999966, 2.3400000000000034, 2.5, 2.219999999999999]\n",
      "Step 4800 (epoch 5.59), 1101.5 ms\n",
      "Minibatch loss: 0.672, learning rate: 0.000774\n",
      "Minibatch error: [3.125, 4.6875, 4.6875, 4.6875, 4.6875]\n",
      "Validation error: [3.6200000000000045, 3.0, 2.739999999999995, 2.3599999999999994, 2.6400000000000006]\n",
      "Step 4900 (epoch 5.70), 1102.5 ms\n",
      "Minibatch loss: 0.219, learning rate: 0.000774\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [2.5400000000000063, 2.0600000000000023, 1.6400000000000006, 1.7000000000000028, 1.6400000000000006]\n",
      "Step 5000 (epoch 5.82), 1100.8 ms\n",
      "Minibatch loss: 0.651, learning rate: 0.000774\n",
      "Minibatch error: [3.125, 3.125, 4.6875, 4.6875, 3.125]\n",
      "Validation error: [2.9000000000000057, 1.8599999999999994, 1.6800000000000068, 1.7600000000000051, 1.8199999999999932]\n",
      "Step 5100 (epoch 5.93), 1096.4 ms\n",
      "Minibatch loss: 0.055, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.280000000000001, 2.0400000000000063, 1.7399999999999949, 1.7999999999999972, 1.8400000000000034]\n",
      "Step 5200 (epoch 6.05), 1103.7 ms\n",
      "Minibatch loss: 0.746, learning rate: 0.000735\n",
      "Minibatch error: [4.6875, 4.6875, 6.25, 3.125, 3.125]\n",
      "Validation error: [3.280000000000001, 2.480000000000004, 2.5, 2.0600000000000023, 2.0400000000000063]\n",
      "Step 5300 (epoch 6.17), 1098.5 ms\n",
      "Minibatch loss: 0.195, learning rate: 0.000735\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 1.5625, 1.5625]\n",
      "Validation error: [2.5799999999999983, 1.8400000000000034, 2.0400000000000063, 1.8400000000000034, 1.980000000000004]\n",
      "Step 5400 (epoch 6.28), 1102.9 ms\n",
      "Minibatch loss: 0.105, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.519999999999996, 1.980000000000004, 1.8400000000000034, 1.6400000000000006, 1.7999999999999972]\n",
      "Step 5500 (epoch 6.40), 1097.6 ms\n",
      "Minibatch loss: 0.223, learning rate: 0.000735\n",
      "Minibatch error: [3.125, 1.5625, 0.0, 1.5625, 1.5625]\n",
      "Validation error: [3.200000000000003, 2.760000000000005, 2.180000000000007, 1.7199999999999989, 1.6800000000000068]\n",
      "Step 5600 (epoch 6.52), 1093.1 ms\n",
      "Minibatch loss: 0.070, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 0.0, 0.0]\n",
      "Validation error: [3.0999999999999943, 2.5999999999999943, 2.6200000000000045, 2.3599999999999994, 2.180000000000007]\n",
      "Step 5700 (epoch 6.63), 1095.8 ms\n",
      "Minibatch loss: 0.183, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 3.125, 1.5625, 0.0, 0.0]\n",
      "Validation error: [4.439999999999998, 5.439999999999998, 5.780000000000001, 6.239999999999995, 4.359999999999999]\n",
      "Step 5800 (epoch 6.75), 1098.3 ms\n",
      "Minibatch loss: 0.262, learning rate: 0.000735\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 0.0, 0.0]\n",
      "Validation error: [2.5400000000000063, 2.219999999999999, 2.1599999999999966, 2.200000000000003, 2.0400000000000063]\n",
      "Step 5900 (epoch 6.87), 1100.4 ms\n",
      "Minibatch loss: 0.094, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.700000000000003, 1.7999999999999972, 1.7000000000000028, 1.480000000000004, 1.5600000000000023]\n",
      "Step 6000 (epoch 6.98), 1099.7 ms\n",
      "Minibatch loss: 0.131, learning rate: 0.000735\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.480000000000004, 1.9599999999999937, 1.7800000000000011, 1.4599999999999937, 1.3599999999999994]\n",
      "Step 6100 (epoch 7.10), 1094.3 ms\n",
      "Minibatch loss: 0.272, learning rate: 0.000698\n",
      "Minibatch error: [1.5625, 3.125, 1.5625, 3.125, 1.5625]\n",
      "Validation error: [4.260000000000005, 3.4399999999999977, 3.260000000000005, 3.260000000000005, 3.219999999999999]\n",
      "Step 6200 (epoch 7.21), 1095.0 ms\n",
      "Minibatch loss: 0.048, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [7.920000000000002, 8.900000000000006, 6.799999999999997, 6.540000000000006, 8.159999999999997]\n",
      "Step 6300 (epoch 7.33), 1099.8 ms\n",
      "Minibatch loss: 0.213, learning rate: 0.000698\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [2.780000000000001, 1.8199999999999932, 1.7800000000000011, 1.7199999999999989, 1.7999999999999972]\n",
      "Step 6400 (epoch 7.45), 1097.2 ms\n",
      "Minibatch loss: 0.588, learning rate: 0.000698\n",
      "Minibatch error: [6.25, 3.125, 3.125, 3.125, 3.125]\n",
      "Validation error: [3.260000000000005, 2.1599999999999966, 1.980000000000004, 1.7800000000000011, 2.019999999999996]\n",
      "Step 6500 (epoch 7.56), 1100.3 ms\n",
      "Minibatch loss: 0.077, learning rate: 0.000698\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.1200000000000045, 1.519999999999996, 1.4599999999999937, 1.3799999999999955, 1.4399999999999977]\n",
      "Step 6600 (epoch 7.68), 1101.7 ms\n",
      "Minibatch loss: 0.405, learning rate: 0.000698\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [2.0400000000000063, 1.8799999999999955, 1.519999999999996, 1.7199999999999989, 1.6200000000000045]\n",
      "Step 6700 (epoch 7.80), 1093.9 ms\n",
      "Minibatch loss: 0.253, learning rate: 0.000698\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.980000000000004, 1.3400000000000034, 1.3199999999999932, 1.1400000000000006, 1.2600000000000051]\n",
      "Step 6800 (epoch 7.91), 1097.2 ms\n",
      "Minibatch loss: 0.066, learning rate: 0.000698\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.9599999999999937, 1.9599999999999937, 1.8799999999999955, 1.6200000000000045, 1.6400000000000006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6900 (epoch 8.03), 1096.5 ms\n",
      "Minibatch loss: 0.083, learning rate: 0.000663\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.239999999999995, 1.6400000000000006, 1.2199999999999989, 1.4399999999999977, 1.1599999999999966]\n",
      "Step 7000 (epoch 8.15), 1098.3 ms\n",
      "Minibatch loss: 0.168, learning rate: 0.000663\n",
      "Minibatch error: [1.5625, 1.5625, 0.0, 0.0, 1.5625]\n",
      "Validation error: [3.9399999999999977, 2.760000000000005, 2.3599999999999994, 2.260000000000005, 2.1599999999999966]\n",
      "Step 7100 (epoch 8.26), 1094.6 ms\n",
      "Minibatch loss: 0.230, learning rate: 0.000663\n",
      "Minibatch error: [3.125, 0.0, 0.0, 0.0, 3.125]\n",
      "Validation error: [2.4200000000000017, 2.0400000000000063, 1.7000000000000028, 1.6200000000000045, 1.519999999999996]\n",
      "Step 7200 (epoch 8.38), 1094.3 ms\n",
      "Minibatch loss: 0.322, learning rate: 0.000663\n",
      "Minibatch error: [3.125, 3.125, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.9599999999999937, 1.8199999999999932, 1.7199999999999989, 1.5, 1.6800000000000068]\n",
      "Step 7300 (epoch 8.49), 1099.3 ms\n",
      "Minibatch loss: 0.251, learning rate: 0.000663\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [2.319999999999993, 1.6800000000000068, 1.4399999999999977, 1.3199999999999932, 1.4599999999999937]\n",
      "Step 7400 (epoch 8.61), 1098.3 ms\n",
      "Minibatch loss: 0.055, learning rate: 0.000663\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.980000000000004, 2.019999999999996, 2.6200000000000045, 2.219999999999999, 2.260000000000005]\n",
      "Step 7500 (epoch 8.73), 1098.5 ms\n",
      "Minibatch loss: 0.096, learning rate: 0.000663\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.3400000000000034, 1.7800000000000011, 1.5600000000000023, 1.4599999999999937, 1.3400000000000034]\n",
      "Step 7600 (epoch 8.84), 1094.9 ms\n",
      "Minibatch loss: 0.607, learning rate: 0.000663\n",
      "Minibatch error: [3.125, 4.6875, 3.125, 3.125, 4.6875]\n",
      "Validation error: [3.180000000000007, 2.0999999999999943, 1.980000000000004, 1.7800000000000011, 2.239999999999995]\n",
      "Step 7700 (epoch 8.96), 1100.7 ms\n",
      "Minibatch loss: 0.032, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.719999999999999, 2.4399999999999977, 2.0400000000000063, 1.8199999999999932, 1.8199999999999932]\n",
      "Step 7800 (epoch 9.08), 1094.2 ms\n",
      "Minibatch loss: 0.494, learning rate: 0.000630\n",
      "Minibatch error: [7.8125, 3.125, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [4.819999999999993, 4.540000000000006, 2.6400000000000006, 2.4599999999999937, 2.4599999999999937]\n",
      "Step 7900 (epoch 9.19), 1091.5 ms\n",
      "Minibatch loss: 0.137, learning rate: 0.000630\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [3.5600000000000023, 2.9000000000000057, 2.1599999999999966, 2.4000000000000057, 2.239999999999995]\n",
      "Step 8000 (epoch 9.31), 1095.1 ms\n",
      "Minibatch loss: 0.079, learning rate: 0.000630\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.9599999999999937, 1.980000000000004, 1.6400000000000006, 1.5799999999999983, 1.519999999999996]\n",
      "Step 8100 (epoch 9.43), 1098.0 ms\n",
      "Minibatch loss: 0.085, learning rate: 0.000630\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [2.260000000000005, 1.7600000000000051, 1.6599999999999966, 1.5799999999999983, 1.6599999999999966]\n",
      "Step 8200 (epoch 9.54), 1101.3 ms\n",
      "Minibatch loss: 0.175, learning rate: 0.000630\n",
      "Minibatch error: [3.125, 1.5625, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.7000000000000028, 1.2600000000000051, 1.2399999999999949, 1.2199999999999989, 1.3799999999999955]\n",
      "Step 8300 (epoch 9.66), 1103.9 ms\n",
      "Minibatch loss: 0.203, learning rate: 0.000630\n",
      "Minibatch error: [3.125, 1.5625, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.9200000000000017, 1.5999999999999943, 1.5600000000000023, 1.3199999999999932, 1.3199999999999932]\n",
      "Step 8400 (epoch 9.77), 1095.0 ms\n",
      "Minibatch loss: 0.038, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.519999999999996, 1.2399999999999949, 1.4599999999999937, 1.4200000000000017, 1.4200000000000017]\n",
      "Step 8500 (epoch 9.89), 1095.8 ms\n",
      "Minibatch loss: 0.066, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.7399999999999949, 1.480000000000004, 1.4399999999999977, 1.2999999999999972, 1.2399999999999949]\n",
      "Test error: [2.6400000000000006, 1.9099999999999966, 1.4000000000000057, 1.480000000000004, 1.4000000000000057]\n",
      "----------------\n",
      "Step 0 (epoch 0.00), 333.4 ms\n",
      "Minibatch loss: 11.530, learning rate: 0.001000Minibatch error: [92.1875, 89.0625, 92.1875, 89.0625, 90.625]Validation error: [90.14, 90.1, 90.14, 89.98, 89.3]Step 100 (epoch 0.12), 1127.4 ms\n",
      "Minibatch loss: 5.007, learning rate: 0.001000Minibatch error: [46.875, 18.75, 15.625, 28.125, 35.9375]Validation error: [58.26, 36.16, 32.31999999999999, 45.12, 37.22]Step 200 (epoch 0.23), 1091.5 ms\n",
      "Minibatch loss: 3.772, learning rate: 0.001000Minibatch error: [48.4375, 20.3125, 14.0625, 20.3125, 14.0625]Validation error: [42.24, 20.560000000000002, 22.299999999999997, 22.519999999999996, 18.78]Step 300 (epoch 0.35), 1092.6 ms\n",
      "Minibatch loss: 2.912, learning rate: 0.001000Minibatch error: [26.5625, 17.1875, 17.1875, 9.375, 10.9375]Validation error: [24.5, 22.900000000000006, 17.0, 18.72, 18.980000000000004]Step 400 (epoch 0.47), 1092.0 ms\n",
      "Minibatch loss: 3.260, learning rate: 0.001000Minibatch error: [25.0, 17.1875, 20.3125, 18.75, 20.3125]Validation error: [30.439999999999998, 24.040000000000006, 23.340000000000003, 26.680000000000007, 28.180000000000007]Step 500 (epoch 0.58), 1094.9 ms\n",
      "Minibatch loss: 2.343, learning rate: 0.001000Minibatch error: [12.5, 9.375, 7.8125, 9.375, 9.375]Validation error: [11.900000000000006, 10.400000000000006, 9.680000000000007, 11.319999999999993, 10.200000000000003]Step 600 (epoch 0.70), 1093.9 ms\n",
      "Minibatch loss: 1.666, learning rate: 0.001000Minibatch error: [9.375, 9.375, 9.375, 10.9375, 9.375]Validation error: [12.060000000000002, 11.659999999999997, 11.319999999999993, 11.5, 13.060000000000002]Step 700 (epoch 0.81), 1102.0 ms\n",
      "Minibatch loss: 1.138, learning rate: 0.001000Minibatch error: [14.0625, 4.6875, 4.6875, 4.6875, 4.6875]Validation error: [12.099999999999994, 7.659999999999997, 7.939999999999998, 8.099999999999994, 7.519999999999996]Step 800 (epoch 0.93), 1101.9 ms\n",
      "Minibatch loss: 1.254, learning rate: 0.001000Minibatch error: [10.9375, 7.8125, 6.25, 6.25, 6.25]Validation error: [10.840000000000003, 5.859999999999999, 6.680000000000007, 6.319999999999993, 6.640000000000001]Step 900 (epoch 1.05), 1101.8 ms\n",
      "Minibatch loss: 0.997, learning rate: 0.000950Minibatch error: [7.8125, 3.125, 3.125, 3.125, 3.125]Validation error: [12.780000000000001, 11.36, 9.5, 10.159999999999997, 9.64]Step 1000 (epoch 1.16), 1094.7 ms\n",
      "Minibatch loss: 1.220, learning rate: 0.000950Minibatch error: [10.9375, 6.25, 7.8125, 7.8125, 7.8125]Validation error: [9.459999999999994, 8.700000000000003, 7.900000000000006, 7.0, 7.099999999999994]Step 1100 (epoch 1.28), 1094.8 ms\n",
      "Minibatch loss: 0.564, learning rate: 0.000950Minibatch error: [4.6875, 3.125, 3.125, 1.5625, 1.5625]Validation error: [21.239999999999995, 11.36, 9.319999999999993, 8.459999999999994, 7.819999999999993]Step 1200 (epoch 1.40), 1093.0 ms\n",
      "Minibatch loss: 0.427, learning rate: 0.000950Minibatch error: [0.0, 0.0, 0.0, 1.5625, 1.5625]Validation error: [6.040000000000006, 4.799999999999997, 4.640000000000001, 4.359999999999999, 4.319999999999993]Step 1300 (epoch 1.51), 1088.1 ms\n",
      "Minibatch loss: 0.752, learning rate: 0.000950Minibatch error: [4.6875, 4.6875, 1.5625, 3.125, 3.125]Validation error: [8.459999999999994, 6.5, 5.6200000000000045, 5.400000000000006, 4.959999999999994]Step 1400 (epoch 1.63), 1093.6 ms\n",
      "Minibatch loss: 1.005, learning rate: 0.000950Minibatch error: [14.0625, 3.125, 3.125, 3.125, 3.125]Validation error: [6.739999999999995, 5.3799999999999955, 5.260000000000005, 5.180000000000007, 4.200000000000003]Step 1500 (epoch 1.75), 1092.6 ms\n",
      "Minibatch loss: 1.345, learning rate: 0.000950Minibatch error: [9.375, 7.8125, 6.25, 6.25, 6.25]Validation error: [5.0, 4.519999999999996, 4.780000000000001, 3.6400000000000006, 3.1400000000000006]Step 1600 (epoch 1.86), 1089.0 ms\n",
      "Minibatch loss: 0.537, learning rate: 0.000950Minibatch error: [3.125, 4.6875, 3.125, 3.125, 3.125]Validation error: [4.1200000000000045, 3.239999999999995, 3.3799999999999955, 3.3599999999999994, 3.0999999999999943]Step 1700 (epoch 1.98), 1098.8 ms\n",
      "Minibatch loss: 0.163, learning rate: 0.000950Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [6.700000000000003, 4.8799999999999955, 4.3799999999999955, 3.8799999999999955, 3.3400000000000034]Step 1800 (epoch 2.09), 1096.2 ms\n",
      "Minibatch loss: 0.253, learning rate: 0.000902Minibatch error: [3.125, 0.0, 0.0, 0.0, 1.5625]Validation error: [7.319999999999993, 4.579999999999998, 4.280000000000001, 3.680000000000007, 3.680000000000007]Step 1900 (epoch 2.21), 1097.0 ms\n",
      "Minibatch loss: 0.454, learning rate: 0.000902Minibatch error: [4.6875, 4.6875, 1.5625, 1.5625, 1.5625]Validation error: [4.459999999999994, 3.0600000000000023, 3.260000000000005, 3.1599999999999966, 3.480000000000004]Step 2000 (epoch 2.33), 1092.9 ms\n",
      "Minibatch loss: 0.205, learning rate: 0.000902Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [5.280000000000001, 4.840000000000003, 4.840000000000003, 4.459999999999994, 4.260000000000005]Step 2100 (epoch 2.44), 1091.6 ms\n",
      "Minibatch loss: 0.706, learning rate: 0.000902Minibatch error: [1.5625, 6.25, 3.125, 4.6875, 3.125]Validation error: [3.9399999999999977, 3.5600000000000023, 3.4399999999999977, 3.239999999999995, 3.0]Step 2200 (epoch 2.56), 1094.0 ms\n",
      "Minibatch loss: 0.351, learning rate: 0.000902Minibatch error: [6.25, 0.0, 0.0, 0.0, 0.0]Validation error: [3.739999999999995, 3.0400000000000063, 2.799999999999997, 2.680000000000007, 2.4599999999999937]Step 2300 (epoch 2.68), 1092.4 ms\n",
      "Minibatch loss: 0.498, learning rate: 0.000902Minibatch error: [6.25, 1.5625, 3.125, 1.5625, 3.125]Validation error: [4.659999999999997, 3.4399999999999977, 3.299999999999997, 2.980000000000004, 2.780000000000001]Step 2400 (epoch 2.79), 1093.1 ms\n",
      "Minibatch loss: 0.124, learning rate: 0.000902Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [4.299999999999997, 3.3599999999999994, 4.099999999999994, 3.819999999999993, 3.5]Step 2500 (epoch 2.91), 1093.8 ms\n",
      "Minibatch loss: 0.145, learning rate: 0.000902Minibatch error: [3.125, 0.0, 0.0, 0.0, 0.0]Validation error: [4.280000000000001, 3.799999999999997, 4.239999999999995, 3.8799999999999955, 4.040000000000006]Step 2600 (epoch 3.03), 1086.8 ms\n",
      "Minibatch loss: 0.207, learning rate: 0.000857Minibatch error: [1.5625, 0.0, 1.5625, 0.0, 0.0]Validation error: [4.299999999999997, 4.5, 4.140000000000001, 3.680000000000007, 2.719999999999999]Step 2700 (epoch 3.14), 1093.1 ms\n",
      "Minibatch loss: 2.660, learning rate: 0.000857Minibatch error: [34.375, 14.0625, 10.9375, 10.9375, 12.5]Validation error: [35.44, 20.799999999999997, 9.019999999999996, 8.019999999999996, 7.659999999999997]Step 2800 (epoch 3.26), 1095.5 ms\n",
      "Minibatch loss: 0.356, learning rate: 0.000857Minibatch error: [1.5625, 0.0, 1.5625, 1.5625, 3.125]Validation error: [3.760000000000005, 2.819999999999993, 2.4599999999999937, 2.4399999999999977, 2.180000000000007]Step 2900 (epoch 3.37), 1090.8 ms\n",
      "Minibatch loss: 0.592, learning rate: 0.000857Minibatch error: [4.6875, 4.6875, 4.6875, 3.125, 1.5625]Validation error: [3.4399999999999977, 2.9599999999999937, 2.680000000000007, 2.4200000000000017, 2.1599999999999966]Step 3000 (epoch 3.49), 1092.9 ms\n",
      "Minibatch loss: 1.058, learning rate: 0.000857Minibatch error: [6.25, 1.5625, 3.125, 3.125, 4.6875]Validation error: [5.819999999999993, 4.8799999999999955, 4.200000000000003, 5.260000000000005, 5.180000000000007]Step 3100 (epoch 3.61), 1093.9 ms\n",
      "Minibatch loss: 0.764, learning rate: 0.000857Minibatch error: [6.25, 3.125, 3.125, 4.6875, 4.6875]Validation error: [3.980000000000004, 3.4399999999999977, 3.180000000000007, 3.0, 2.739999999999995]Step 3200 (epoch 3.72), 1091.0 ms\n",
      "Minibatch loss: 0.406, learning rate: 0.000857Minibatch error: [3.125, 0.0, 3.125, 4.6875, 1.5625]Validation error: [3.200000000000003, 3.0, 2.5400000000000063, 2.480000000000004, 2.180000000000007]Step 3300 (epoch 3.84), 1092.4 ms\n",
      "Minibatch loss: 0.237, learning rate: 0.000857Minibatch error: [3.125, 1.5625, 3.125, 1.5625, 1.5625]Validation error: [4.599999999999994, 4.060000000000002, 3.180000000000007, 3.1400000000000006, 2.680000000000007]Step 3400 (epoch 3.96), 1089.9 ms\n",
      "Minibatch loss: 0.366, learning rate: 0.000857Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [3.980000000000004, 2.799999999999997, 2.8599999999999994, 2.739999999999995, 2.5799999999999983]Step 3500 (epoch 4.07), 1093.9 ms\n",
      "Minibatch loss: 0.394, learning rate: 0.000815Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 3.125]Validation error: [6.400000000000006, 5.340000000000003, 4.859999999999999, 3.6599999999999966, 3.819999999999993]Step 3600 (epoch 4.19), 1096.7 ms\n",
      "Minibatch loss: 0.038, learning rate: 0.000815Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [3.180000000000007, 2.4399999999999977, 2.4200000000000017, 2.3799999999999955, 2.0400000000000063]Step 3700 (epoch 4.31), 1098.4 ms\n",
      "Minibatch loss: 0.069, learning rate: 0.000815Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [3.019999999999996, 2.4000000000000057, 2.5, 2.0400000000000063, 2.180000000000007]Step 3800 (epoch 4.42), 1093.7 ms\n",
      "Minibatch loss: 0.452, learning rate: 0.000815Minibatch error: [4.6875, 4.6875, 1.5625, 1.5625, 3.125]Validation error: [2.9200000000000017, 3.1400000000000006, 2.5, 2.3799999999999955, 2.280000000000001]Step 3900 (epoch 4.54), 1092.7 ms\n",
      "Minibatch loss: 0.356, learning rate: 0.000815Minibatch error: [3.125, 4.6875, 1.5625, 1.5625, 0.0]Validation error: [2.299999999999997, 1.7999999999999972, 1.7800000000000011, 1.6800000000000068, 1.6200000000000045]Step 4000 (epoch 4.65), 1090.8 ms\n",
      "Minibatch loss: 0.790, learning rate: 0.000815Minibatch error: [3.125, 4.6875, 3.125, 3.125, 3.125]Validation error: [2.3599999999999994, 2.319999999999993, 2.0400000000000063, 2.0600000000000023, 2.0999999999999943]Step 4100 (epoch 4.77), 1090.9 ms\n",
      "Minibatch loss: 0.632, learning rate: 0.000815Minibatch error: [3.125, 3.125, 3.125, 3.125, 3.125]Validation error: [3.9599999999999937, 2.680000000000007, 3.1200000000000045, 2.6599999999999966, 2.719999999999999]Step 4200 (epoch 4.89), 1097.9 ms\n",
      "Minibatch loss: 0.490, learning rate: 0.000815Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [2.8599999999999994, 1.9399999999999977, 2.0400000000000063, 1.8599999999999994, 1.7199999999999989]Step 4300 (epoch 5.00), 1099.6 ms\n",
      "Minibatch loss: 0.260, learning rate: 0.000774Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [2.799999999999997, 2.3400000000000034, 1.7399999999999949, 1.6400000000000006, 1.6599999999999966]Step 4400 (epoch 5.12), 1091.0 ms\n",
      "Minibatch loss: 0.313, learning rate: 0.000774Minibatch error: [3.125, 1.5625, 1.5625, 3.125, 3.125]Validation error: [6.280000000000001, 3.239999999999995, 2.700000000000003, 3.019999999999996, 2.9399999999999977]Step 4500 (epoch 5.24), 1097.3 ms\n",
      "Minibatch loss: 0.555, learning rate: 0.000774Minibatch error: [6.25, 4.6875, 4.6875, 4.6875, 3.125]Validation error: [3.9599999999999937, 2.8799999999999955, 2.6200000000000045, 2.5, 2.480000000000004]Step 4600 (epoch 5.35), 1100.7 ms\n",
      "Minibatch loss: 0.064, learning rate: 0.000774Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [2.680000000000007, 2.0600000000000023, 1.6400000000000006, 1.8799999999999955, 1.7800000000000011]Step 4700 (epoch 5.47), 1097.0 ms\n",
      "Minibatch loss: 0.076, learning rate: 0.000774Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [2.9599999999999937, 2.6599999999999966, 2.3400000000000034, 2.5, 2.219999999999999]Step 4800 (epoch 5.59), 1101.5 ms\n",
      "Minibatch loss: 0.672, learning rate: 0.000774Minibatch error: [3.125, 4.6875, 4.6875, 4.6875, 4.6875]Validation error: [3.6200000000000045, 3.0, 2.739999999999995, 2.3599999999999994, 2.6400000000000006]Step 4900 (epoch 5.70), 1102.5 ms\n",
      "Minibatch loss: 0.219, learning rate: 0.000774Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [2.5400000000000063, 2.0600000000000023, 1.6400000000000006, 1.7000000000000028, 1.6400000000000006]Step 5000 (epoch 5.82), 1100.8 ms\n",
      "Minibatch loss: 0.651, learning rate: 0.000774Minibatch error: [3.125, 3.125, 4.6875, 4.6875, 3.125]Validation error: [2.9000000000000057, 1.8599999999999994, 1.6800000000000068, 1.7600000000000051, 1.8199999999999932]Step 5100 (epoch 5.93), 1096.4 ms\n",
      "Minibatch loss: 0.055, learning rate: 0.000774Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [2.280000000000001, 2.0400000000000063, 1.7399999999999949, 1.7999999999999972, 1.8400000000000034]Step 5200 (epoch 6.05), 1103.7 ms\n",
      "Minibatch loss: 0.746, learning rate: 0.000735Minibatch error: [4.6875, 4.6875, 6.25, 3.125, 3.125]Validation error: [3.280000000000001, 2.480000000000004, 2.5, 2.0600000000000023, 2.0400000000000063]Step 5300 (epoch 6.17), 1098.5 ms\n",
      "Minibatch loss: 0.195, learning rate: 0.000735Minibatch error: [1.5625, 0.0, 0.0, 1.5625, 1.5625]Validation error: [2.5799999999999983, 1.8400000000000034, 2.0400000000000063, 1.8400000000000034, 1.980000000000004]Step 5400 (epoch 6.28), 1102.9 ms\n",
      "Minibatch loss: 0.105, learning rate: 0.000735Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [2.519999999999996, 1.980000000000004, 1.8400000000000034, 1.6400000000000006, 1.7999999999999972]Step 5500 (epoch 6.40), 1097.6 ms\n",
      "Minibatch loss: 0.223, learning rate: 0.000735Minibatch error: [3.125, 1.5625, 0.0, 1.5625, 1.5625]Validation error: [3.200000000000003, 2.760000000000005, 2.180000000000007, 1.7199999999999989, 1.6800000000000068]Step 5600 (epoch 6.52), 1093.1 ms\n",
      "Minibatch loss: 0.070, learning rate: 0.000735Minibatch error: [0.0, 0.0, 1.5625, 0.0, 0.0]Validation error: [3.0999999999999943, 2.5999999999999943, 2.6200000000000045, 2.3599999999999994, 2.180000000000007]Step 5700 (epoch 6.63), 1095.8 ms\n",
      "Minibatch loss: 0.183, learning rate: 0.000735Minibatch error: [0.0, 3.125, 1.5625, 0.0, 0.0]Validation error: [4.439999999999998, 5.439999999999998, 5.780000000000001, 6.239999999999995, 4.359999999999999]Step 5800 (epoch 6.75), 1098.3 ms\n",
      "Minibatch loss: 0.262, learning rate: 0.000735Minibatch error: [1.5625, 1.5625, 1.5625, 0.0, 0.0]Validation error: [2.5400000000000063, 2.219999999999999, 2.1599999999999966, 2.200000000000003, 2.0400000000000063]Step 5900 (epoch 6.87), 1100.4 ms\n",
      "Minibatch loss: 0.094, learning rate: 0.000735Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [2.700000000000003, 1.7999999999999972, 1.7000000000000028, 1.480000000000004, 1.5600000000000023]Step 6000 (epoch 6.98), 1099.7 ms\n",
      "Minibatch loss: 0.131, learning rate: 0.000735Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.480000000000004, 1.9599999999999937, 1.7800000000000011, 1.4599999999999937, 1.3599999999999994]Step 6100 (epoch 7.10), 1094.3 ms\n",
      "Minibatch loss: 0.272, learning rate: 0.000698Minibatch error: [1.5625, 3.125, 1.5625, 3.125, 1.5625]Validation error: [4.260000000000005, 3.4399999999999977, 3.260000000000005, 3.260000000000005, 3.219999999999999]Step 6200 (epoch 7.21), 1095.0 ms\n",
      "Minibatch loss: 0.048, learning rate: 0.000698Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [7.920000000000002, 8.900000000000006, 6.799999999999997, 6.540000000000006, 8.159999999999997]Step 6300 (epoch 7.33), 1099.8 ms\n",
      "Minibatch loss: 0.213, learning rate: 0.000698Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [2.780000000000001, 1.8199999999999932, 1.7800000000000011, 1.7199999999999989, 1.7999999999999972]Step 6400 (epoch 7.45), 1097.2 ms\n",
      "Minibatch loss: 0.588, learning rate: 0.000698Minibatch error: [6.25, 3.125, 3.125, 3.125, 3.125]Validation error: [3.260000000000005, 2.1599999999999966, 1.980000000000004, 1.7800000000000011, 2.019999999999996]Step 6500 (epoch 7.56), 1100.3 ms\n",
      "Minibatch loss: 0.077, learning rate: 0.000698Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.1200000000000045, 1.519999999999996, 1.4599999999999937, 1.3799999999999955, 1.4399999999999977]Step 6600 (epoch 7.68), 1101.7 ms\n",
      "Minibatch loss: 0.405, learning rate: 0.000698Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [2.0400000000000063, 1.8799999999999955, 1.519999999999996, 1.7199999999999989, 1.6200000000000045]Step 6700 (epoch 7.80), 1093.9 ms\n",
      "Minibatch loss: 0.253, learning rate: 0.000698Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [1.980000000000004, 1.3400000000000034, 1.3199999999999932, 1.1400000000000006, 1.2600000000000051]Step 6800 (epoch 7.91), 1097.2 ms\n",
      "Minibatch loss: 0.066, learning rate: 0.000698Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.9599999999999937, 1.9599999999999937, 1.8799999999999955, 1.6200000000000045, 1.6400000000000006]Step 6900 (epoch 8.03), 1096.5 ms\n",
      "Minibatch loss: 0.083, learning rate: 0.000663Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.239999999999995, 1.6400000000000006, 1.2199999999999989, 1.4399999999999977, 1.1599999999999966]Step 7000 (epoch 8.15), 1098.3 ms\n",
      "Minibatch loss: 0.168, learning rate: 0.000663Minibatch error: [1.5625, 1.5625, 0.0, 0.0, 1.5625]Validation error: [3.9399999999999977, 2.760000000000005, 2.3599999999999994, 2.260000000000005, 2.1599999999999966]Step 7100 (epoch 8.26), 1094.6 ms\n",
      "Minibatch loss: 0.230, learning rate: 0.000663Minibatch error: [3.125, 0.0, 0.0, 0.0, 3.125]Validation error: [2.4200000000000017, 2.0400000000000063, 1.7000000000000028, 1.6200000000000045, 1.519999999999996]Step 7200 (epoch 8.38), 1094.3 ms\n",
      "Minibatch loss: 0.322, learning rate: 0.000663Minibatch error: [3.125, 3.125, 1.5625, 1.5625, 1.5625]Validation error: [1.9599999999999937, 1.8199999999999932, 1.7199999999999989, 1.5, 1.6800000000000068]Step 7300 (epoch 8.49), 1099.3 ms\n",
      "Minibatch loss: 0.251, learning rate: 0.000663Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]Validation error: [2.319999999999993, 1.6800000000000068, 1.4399999999999977, 1.3199999999999932, 1.4599999999999937]Step 7400 (epoch 8.61), 1098.3 ms\n",
      "Minibatch loss: 0.055, learning rate: 0.000663Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.980000000000004, 2.019999999999996, 2.6200000000000045, 2.219999999999999, 2.260000000000005]Step 7500 (epoch 8.73), 1098.5 ms\n",
      "Minibatch loss: 0.096, learning rate: 0.000663Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.3400000000000034, 1.7800000000000011, 1.5600000000000023, 1.4599999999999937, 1.3400000000000034]Step 7600 (epoch 8.84), 1094.9 ms\n",
      "Minibatch loss: 0.607, learning rate: 0.000663Minibatch error: [3.125, 4.6875, 3.125, 3.125, 4.6875]Validation error: [3.180000000000007, 2.0999999999999943, 1.980000000000004, 1.7800000000000011, 2.239999999999995]Step 7700 (epoch 8.96), 1100.7 ms\n",
      "Minibatch loss: 0.032, learning rate: 0.000663Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [2.719999999999999, 2.4399999999999977, 2.0400000000000063, 1.8199999999999932, 1.8199999999999932]Step 7800 (epoch 9.08), 1094.2 ms\n",
      "Minibatch loss: 0.494, learning rate: 0.000630Minibatch error: [7.8125, 3.125, 1.5625, 1.5625, 1.5625]Validation error: [4.819999999999993, 4.540000000000006, 2.6400000000000006, 2.4599999999999937, 2.4599999999999937]Step 7900 (epoch 9.19), 1091.5 ms\n",
      "Minibatch loss: 0.137, learning rate: 0.000630Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [3.5600000000000023, 2.9000000000000057, 2.1599999999999966, 2.4000000000000057, 2.239999999999995]Step 8000 (epoch 9.31), 1095.1 ms\n",
      "Minibatch loss: 0.079, learning rate: 0.000630Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]Validation error: [2.9599999999999937, 1.980000000000004, 1.6400000000000006, 1.5799999999999983, 1.519999999999996]Step 8100 (epoch 9.43), 1098.0 ms\n",
      "Minibatch loss: 0.085, learning rate: 0.000630Minibatch error: [1.5625, 0.0, 0.0, 0.0, 1.5625]Validation error: [2.260000000000005, 1.7600000000000051, 1.6599999999999966, 1.5799999999999983, 1.6599999999999966]Step 8200 (epoch 9.54), 1101.3 ms\n",
      "Minibatch loss: 0.175, learning rate: 0.000630Minibatch error: [3.125, 1.5625, 0.0, 0.0, 0.0]Validation error: [1.7000000000000028, 1.2600000000000051, 1.2399999999999949, 1.2199999999999989, 1.3799999999999955]Step 8300 (epoch 9.66), 1103.9 ms\n",
      "Minibatch loss: 0.203, learning rate: 0.000630Minibatch error: [3.125, 1.5625, 0.0, 0.0, 0.0]Validation error: [1.9200000000000017, 1.5999999999999943, 1.5600000000000023, 1.3199999999999932, 1.3199999999999932]Step 8400 (epoch 9.77), 1095.0 ms\n",
      "Minibatch loss: 0.038, learning rate: 0.000630Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [1.519999999999996, 1.2399999999999949, 1.4599999999999937, 1.4200000000000017, 1.4200000000000017]Step 8500 (epoch 9.89), 1095.8 ms\n",
      "Minibatch loss: 0.066, learning rate: 0.000630Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]Validation error: [1.7399999999999949, 1.480000000000004, 1.4399999999999977, 1.2999999999999972, 1.2399999999999949]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    1e-3,                # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "    train_prediction, loss = apply(train_data_node, training=True)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
    "                                                   global_step=batch)\n",
    "\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    eval_prediction, _ = apply(eval_data, training=False)\n",
    "  # Small utility function to evaluate a dataset by feeding batches of data to\n",
    "  # {eval_data} and pulling the results from {eval_predictions}.\n",
    "  # Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(NUM_UNROLL_STEPS, size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[:, begin:end, :] = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[begin:end, ...]})\n",
    "        else:\n",
    "            batch_predictions = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "            predictions[:, begin:, :] = batch_predictions[:, begin - size:, :]\n",
    "    return predictions\n",
    "\n",
    "lines = []\n",
    "\n",
    "  # Create a local session to run the training.\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE):\n",
    "      # Compute the offset of the current minibatch in the data.\n",
    "      # Note that we could use better randomization across epochs.\n",
    "      offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "      batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "      batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "      # This dictionary maps the batch data (as a numpy array) to the\n",
    "      # node in the graph it should be fed to.\n",
    "      feed_dict = {train_data_node: batch_data,\n",
    "                   train_labels_node: batch_labels}\n",
    "      # Run the optimizer to update weights.\n",
    "      sess.run(optimizer, feed_dict=feed_dict)\n",
    "      # print some extra information once reach the evaluation frequency\n",
    "      if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        l, lr, predictions = sess.run([loss, learning_rate, train_prediction],\n",
    "                                      feed_dict=feed_dict)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lines.append('Step %d (epoch %.2f), %.1f ms\\n' %\n",
    "              (step, float(step) * BATCH_SIZE / train_size,\n",
    "               1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch loss: %.3f, learning rate: %.6f' % (l, lr))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch error: {}'.format(error_rate(predictions, batch_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Validation error: {}'.format(error_rate(\n",
    "            eval_in_batches(validation_data, sess), validation_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "    print('Test error: {}'.format(test_error))\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"\".join(lines))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(input_images, prior, batch_size, training, use_priors):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    \n",
    "    if use_priors:\n",
    "        prior = tf.expand_dims(tf.expand_dims(prior, axis=1), axis=1) # (BATCH_SIZE, 1, 1, NUM_LABELS)\n",
    "        prior = tf.tile(prior, [1, IMAGE_SIZE, IMAGE_SIZE, 1]) # (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_LABELS)\n",
    "        inputs = tf.concat([prior, input_images], axis=3)\n",
    "    else:\n",
    "        inputs = input_images\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=inputs,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_shape = pool2.get_shape()\n",
    "\n",
    "    pool2_flat = tf.reshape(pool2, [-1, pool2_shape[1] * pool2_shape[2] * pool2_shape[3]])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=training)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dropout, units=NUM_LABELS)\n",
    "    posteriors = tf.nn.softmax(logits)\n",
    "    \n",
    "    return logits, posteriors\n",
    "\n",
    "def apply(input_images, training, use_priors):\n",
    "    results = []\n",
    "    loss = 0.0\n",
    "\n",
    "    batch_size = input_images.get_shape()[0]\n",
    "    priors = numpy.array([[1/NUM_LABELS for _ in range(NUM_LABELS)] for _ in range(batch_size)],\n",
    "                         dtype=numpy.float32)\n",
    "    for step in range(NUM_UNROLL_STEPS):\n",
    "        with tf.variable_scope('one_step', reuse=(step > 0)):\n",
    "            logits, posteriors = model_step(input_images, priors, batch_size, training=training, use_priors=use_priors)\n",
    "        priors = posteriors\n",
    "        results.append((logits, posteriors))\n",
    "        loss += tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=train_labels_node, logits=logits))\n",
    "    return tf.stack([logits for (logits, _) in results]), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Step 0 (epoch 0.00), 3.3 ms\n",
      "Minibatch loss: 10.775, learning rate: 0.001000\n",
      "Minibatch error: [84.375, 81.25, 82.8125, 85.9375, 84.375]\n",
      "Validation error: [90.76, 90.76, 90.76, 90.76, 90.76]\n",
      "Step 100 (epoch 0.12), 39.9 ms\n",
      "Minibatch loss: 0.302, learning rate: 0.001000\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 3.125, 1.5625]\n",
      "Validation error: [5.079999999999998, 5.079999999999998, 5.079999999999998, 5.079999999999998, 5.079999999999998]\n",
      "Step 200 (epoch 0.23), 39.0 ms\n",
      "Minibatch loss: 0.638, learning rate: 0.001000\n",
      "Minibatch error: [7.8125, 3.125, 4.6875, 7.8125, 4.6875]\n",
      "Validation error: [2.6599999999999966, 2.6599999999999966, 2.6599999999999966, 2.6599999999999966, 2.6599999999999966]\n",
      "Step 300 (epoch 0.35), 39.1 ms\n",
      "Minibatch loss: 0.608, learning rate: 0.001000\n",
      "Minibatch error: [3.125, 3.125, 3.125, 3.125, 3.125]\n",
      "Validation error: [2.239999999999995, 2.239999999999995, 2.239999999999995, 2.239999999999995, 2.239999999999995]\n",
      "Step 400 (epoch 0.47), 39.1 ms\n",
      "Minibatch loss: 0.601, learning rate: 0.001000\n",
      "Minibatch error: [6.25, 4.6875, 6.25, 6.25, 3.125]\n",
      "Validation error: [1.7800000000000011, 1.7800000000000011, 1.7800000000000011, 1.7800000000000011, 1.7800000000000011]\n",
      "Step 500 (epoch 0.58), 39.0 ms\n",
      "Minibatch loss: 0.859, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 4.6875, 6.25, 4.6875, 4.6875]\n",
      "Validation error: [1.9200000000000017, 1.9200000000000017, 1.9200000000000017, 1.9200000000000017, 1.9200000000000017]\n",
      "Step 600 (epoch 0.70), 39.1 ms\n",
      "Minibatch loss: 0.591, learning rate: 0.001000\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.5999999999999943, 1.5999999999999943, 1.5999999999999943, 1.5999999999999943, 1.5999999999999943]\n",
      "Step 700 (epoch 0.81), 39.1 ms\n",
      "Minibatch loss: 0.153, learning rate: 0.001000\n",
      "Minibatch error: [0.0, 1.5625, 0.0, 1.5625, 1.5625]\n",
      "Validation error: [1.8599999999999994, 1.8599999999999994, 1.8599999999999994, 1.8599999999999994, 1.8599999999999994]\n",
      "Step 800 (epoch 0.93), 39.1 ms\n",
      "Minibatch loss: 0.140, learning rate: 0.001000\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 0.0, 1.5625]\n",
      "Validation error: [1.8799999999999955, 1.8799999999999955, 1.8799999999999955, 1.8799999999999955, 1.8799999999999955]\n",
      "Step 900 (epoch 1.05), 39.0 ms\n",
      "Minibatch loss: 0.034, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.3599999999999994, 1.3599999999999994, 1.3599999999999994, 1.3599999999999994, 1.3599999999999994]\n",
      "Step 1000 (epoch 1.16), 39.0 ms\n",
      "Minibatch loss: 0.082, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 1.5625, 0.0]\n",
      "Validation error: [1.0799999999999983, 1.0799999999999983, 1.0799999999999983, 1.0799999999999983, 1.0799999999999983]\n",
      "Step 1100 (epoch 1.28), 39.1 ms\n",
      "Minibatch loss: 0.010, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.4000000000000057, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057]\n",
      "Step 1200 (epoch 1.40), 39.1 ms\n",
      "Minibatch loss: 0.155, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 1.5625, 0.0, 1.5625, 1.5625]\n",
      "Validation error: [1.1400000000000006, 1.1400000000000006, 1.1400000000000006, 1.1400000000000006, 1.1400000000000006]\n",
      "Step 1300 (epoch 1.51), 39.0 ms\n",
      "Minibatch loss: 0.120, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 1.5625, 0.0, 1.5625, 1.5625]\n",
      "Validation error: [1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011]\n",
      "Step 1400 (epoch 1.63), 38.9 ms\n",
      "Minibatch loss: 0.099, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.4000000000000057, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057]\n",
      "Step 1500 (epoch 1.75), 38.9 ms\n",
      "Minibatch loss: 0.201, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 1.5625, 3.125, 3.125, 3.125]\n",
      "Validation error: [1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 1600 (epoch 1.86), 39.0 ms\n",
      "Minibatch loss: 0.017, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2000000000000028, 1.2000000000000028, 1.2000000000000028, 1.2000000000000028, 1.2000000000000028]\n",
      "Step 1700 (epoch 1.98), 39.0 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1400000000000006, 1.1400000000000006, 1.1400000000000006, 1.1400000000000006, 1.1400000000000006]\n",
      "Step 1800 (epoch 2.09), 39.0 ms\n",
      "Minibatch loss: 0.150, learning rate: 0.000902\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045]\n",
      "Step 1900 (epoch 2.21), 39.0 ms\n",
      "Minibatch loss: 0.021, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Step 2000 (epoch 2.33), 39.0 ms\n",
      "Minibatch loss: 0.092, learning rate: 0.000902\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 2100 (epoch 2.44), 39.0 ms\n",
      "Minibatch loss: 0.022, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 2200 (epoch 2.56), 39.0 ms\n",
      "Minibatch loss: 0.053, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 2300 (epoch 2.68), 39.1 ms\n",
      "Minibatch loss: 0.039, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [0.8400000000000034, 0.8400000000000034, 0.8400000000000034, 0.8400000000000034, 0.8400000000000034]\n",
      "Step 2400 (epoch 2.79), 39.1 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996]\n",
      "Step 2500 (epoch 2.91), 39.1 ms\n",
      "Minibatch loss: 0.016, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011]\n",
      "Step 2600 (epoch 3.03), 39.1 ms\n",
      "Minibatch loss: 0.014, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 2700 (epoch 3.14), 39.1 ms\n",
      "Minibatch loss: 0.043, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011]\n",
      "Step 2800 (epoch 3.26), 39.0 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0799999999999983, 1.0799999999999983, 1.0799999999999983, 1.0799999999999983, 1.0799999999999983]\n",
      "Step 2900 (epoch 3.37), 39.2 ms\n",
      "Minibatch loss: 0.008, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 3000 (epoch 3.49), 39.2 ms\n",
      "Minibatch loss: 0.017, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 3100 (epoch 3.61), 39.0 ms\n",
      "Minibatch loss: 0.029, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 3200 (epoch 3.72), 38.9 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 3300 (epoch 3.84), 39.0 ms\n",
      "Minibatch loss: 0.015, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3400 (epoch 3.96), 39.0 ms\n",
      "Minibatch loss: 0.005, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011]\n",
      "Step 3500 (epoch 4.07), 38.9 ms\n",
      "Minibatch loss: 0.005, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 3600 (epoch 4.19), 39.0 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949]\n",
      "Step 3700 (epoch 4.31), 38.9 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 3800 (epoch 4.42), 39.0 ms\n",
      "Minibatch loss: 0.017, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 3900 (epoch 4.54), 39.1 ms\n",
      "Minibatch loss: 0.025, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051]\n",
      "Step 4000 (epoch 4.65), 39.1 ms\n",
      "Minibatch loss: 0.087, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 1.5625, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 4100 (epoch 4.77), 39.1 ms\n",
      "Minibatch loss: 0.018, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 4200 (epoch 4.89), 39.1 ms\n",
      "Minibatch loss: 0.026, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 1.5625, 0.0]\n",
      "Validation error: [1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045]\n",
      "Step 4300 (epoch 5.00), 39.1 ms\n",
      "Minibatch loss: 0.009, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045]\n",
      "Step 4400 (epoch 5.12), 39.0 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Step 4500 (epoch 5.24), 39.1 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057]\n",
      "Step 4600 (epoch 5.35), 39.1 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 4700 (epoch 5.47), 39.1 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 4800 (epoch 5.59), 39.0 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051]\n",
      "Step 4900 (epoch 5.70), 39.0 ms\n",
      "Minibatch loss: 0.023, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 5000 (epoch 5.82), 39.1 ms\n",
      "Minibatch loss: 0.009, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 5100 (epoch 5.93), 39.1 ms\n",
      "Minibatch loss: 0.077, learning rate: 0.000774\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 0.0, 0.0]\n",
      "Validation error: [1.1800000000000068, 1.1800000000000068, 1.1800000000000068, 1.1800000000000068, 1.1800000000000068]\n",
      "Step 5200 (epoch 6.05), 39.1 ms\n",
      "Minibatch loss: 0.005, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 5300 (epoch 6.17), 39.1 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Step 5400 (epoch 6.28), 39.1 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6599999999999966, 0.6599999999999966, 0.6599999999999966, 0.6599999999999966, 0.6599999999999966]\n",
      "Step 5500 (epoch 6.40), 39.0 ms\n",
      "Minibatch loss: 0.010, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 5600 (epoch 6.52), 39.1 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7199999999999989, 0.7199999999999989, 0.7199999999999989, 0.7199999999999989, 0.7199999999999989]\n",
      "Step 5700 (epoch 6.63), 39.0 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011]\n",
      "Step 5800 (epoch 6.75), 39.0 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 5900 (epoch 6.87), 39.0 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057]\n",
      "Step 6000 (epoch 6.98), 39.1 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949]\n",
      "Step 6100 (epoch 7.10), 39.2 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949]\n",
      "Step 6200 (epoch 7.21), 39.0 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 6300 (epoch 7.33), 39.1 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7199999999999989, 0.7199999999999989, 0.7199999999999989, 0.7199999999999989, 0.7199999999999989]\n",
      "Step 6400 (epoch 7.45), 39.0 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.7999999999999972, 0.7999999999999972, 0.7999999999999972, 0.7999999999999972]\n",
      "Step 6500 (epoch 7.56), 39.0 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051]\n",
      "Step 6600 (epoch 7.68), 38.9 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045]\n",
      "Step 6700 (epoch 7.80), 39.0 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045]\n",
      "Step 6800 (epoch 7.91), 39.1 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6900 (epoch 8.03), 39.1 ms\n",
      "Minibatch loss: 0.030, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 7000 (epoch 8.15), 39.2 ms\n",
      "Minibatch loss: 0.023, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 7100 (epoch 8.26), 39.3 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.7999999999999972, 0.7999999999999972, 0.7999999999999972, 0.7999999999999972]\n",
      "Step 7200 (epoch 8.38), 39.2 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057]\n",
      "Step 7300 (epoch 8.49), 39.3 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949]\n",
      "Step 7400 (epoch 8.61), 39.2 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 7500 (epoch 8.73), 39.2 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011]\n",
      "Step 7600 (epoch 8.84), 39.2 ms\n",
      "Minibatch loss: 0.025, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051]\n",
      "Step 7700 (epoch 8.96), 39.2 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 7800 (epoch 9.08), 39.2 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 7900 (epoch 9.19), 39.1 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 8000 (epoch 9.31), 39.1 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7199999999999989, 0.7199999999999989, 0.7199999999999989, 0.7199999999999989, 0.7199999999999989]\n",
      "Step 8100 (epoch 9.43), 39.2 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045]\n",
      "Step 8200 (epoch 9.54), 39.2 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045, 0.6200000000000045]\n",
      "Step 8300 (epoch 9.66), 39.2 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6800000000000068, 0.6800000000000068, 0.6800000000000068, 0.6800000000000068, 0.6800000000000068]\n",
      "Step 8400 (epoch 9.77), 39.2 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051]\n",
      "Step 8500 (epoch 9.89), 39.1 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011, 0.7800000000000011]\n",
      "Test error: [0.980000000000004, 0.980000000000004, 0.980000000000004, 0.980000000000004, 0.980000000000004]\n"
     ]
    }
   ],
   "source": [
    "use_priors = False\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    1e-3,                # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "    train_prediction, loss = apply(train_data_node, training=True, use_priors=use_priors)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
    "                                                   global_step=batch)\n",
    "\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    eval_prediction, _ = apply(eval_data, training=False, use_priors=use_priors)\n",
    "  # Small utility function to evaluate a dataset by feeding batches of data to\n",
    "  # {eval_data} and pulling the results from {eval_predictions}.\n",
    "  # Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(NUM_UNROLL_STEPS, size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[:, begin:end, :] = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[begin:end, ...]})\n",
    "        else:\n",
    "            batch_predictions = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "            predictions[:, begin:, :] = batch_predictions[:, begin - size:, :]\n",
    "    return predictions\n",
    "\n",
    "lines = []\n",
    "\n",
    "# Create a local session to run the training.\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:    \n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    \n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE):\n",
    "      # Compute the offset of the current minibatch in the data.\n",
    "      # Note that we could use better randomization across epochs.\n",
    "      offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "      batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "      batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "      # This dictionary maps the batch data (as a numpy array) to the\n",
    "      # node in the graph it should be fed to.\n",
    "      feed_dict = {train_data_node: batch_data,\n",
    "                   train_labels_node: batch_labels}\n",
    "      # Run the optimizer to update weights.\n",
    "      sess.run(optimizer, feed_dict=feed_dict)\n",
    "      # print some extra information once reach the evaluation frequency\n",
    "      if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        l, lr, predictions = sess.run([loss, learning_rate, train_prediction],\n",
    "                                      feed_dict=feed_dict)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lines.append('Step %d (epoch %.2f), %.1f ms\\n' %\n",
    "              (step, float(step) * BATCH_SIZE / train_size,\n",
    "               1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch loss: %.3f, learning rate: %.6f\\n' % (l, lr))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch error: {}\\n'.format(error_rate(predictions, batch_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Validation error: {}\\n'.format(error_rate(\n",
    "            eval_in_batches(validation_data, sess), validation_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "    print('Test error: {}'.format(test_error))\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(\"\".join(lines))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Step 0 (epoch 0.00), 4.4 ms\n",
      "Minibatch loss: 10.942, learning rate: 0.001000\n",
      "Minibatch error: [73.4375, 79.6875, 82.8125, 79.6875, 78.125]\n",
      "Validation error: [90.76, 90.76, 90.76, 90.76, 90.76]\n",
      "Step 100 (epoch 0.12), 68.4 ms\n",
      "Minibatch loss: 0.603, learning rate: 0.001000\n",
      "Minibatch error: [1.5625, 3.125, 3.125, 3.125, 1.5625]\n",
      "Validation error: [5.560000000000002, 5.859999999999999, 5.8799999999999955, 6.0, 6.019999999999996]\n",
      "Step 200 (epoch 0.23), 67.3 ms\n",
      "Minibatch loss: 0.830, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 6.25, 6.25, 6.25, 3.125]\n",
      "Validation error: [3.5799999999999983, 3.4599999999999937, 3.4599999999999937, 3.4399999999999977, 3.4599999999999937]\n",
      "Step 300 (epoch 0.35), 67.3 ms\n",
      "Minibatch loss: 0.254, learning rate: 0.001000\n",
      "Minibatch error: [3.125, 1.5625, 0.0, 0.0, 0.0]\n",
      "Validation error: [2.6200000000000045, 2.5600000000000023, 2.4000000000000057, 2.4000000000000057, 2.3599999999999994]\n",
      "Step 400 (epoch 0.47), 67.3 ms\n",
      "Minibatch loss: 0.783, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 4.6875, 4.6875, 6.25, 6.25]\n",
      "Validation error: [1.9599999999999937, 2.019999999999996, 2.0, 2.019999999999996, 2.0400000000000063]\n",
      "Step 500 (epoch 0.58), 67.3 ms\n",
      "Minibatch loss: 0.971, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 3.125, 4.6875, 4.6875, 4.6875]\n",
      "Validation error: [1.9000000000000057, 1.9000000000000057, 1.9000000000000057, 1.9000000000000057, 1.9000000000000057]\n",
      "Step 600 (epoch 0.70), 67.5 ms\n",
      "Minibatch loss: 0.507, learning rate: 0.001000\n",
      "Minibatch error: [1.5625, 1.5625, 3.125, 1.5625, 1.5625]\n",
      "Validation error: [1.7199999999999989, 1.7600000000000051, 1.7199999999999989, 1.7199999999999989, 1.7199999999999989]\n",
      "Step 700 (epoch 0.81), 67.4 ms\n",
      "Minibatch loss: 0.064, learning rate: 0.001000\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.8400000000000034, 1.9399999999999977, 2.0400000000000063, 2.0400000000000063, 2.0400000000000063]\n",
      "Step 800 (epoch 0.93), 67.4 ms\n",
      "Minibatch loss: 0.169, learning rate: 0.001000\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 3.125]\n",
      "Validation error: [2.0600000000000023, 2.0799999999999983, 2.0600000000000023, 2.0600000000000023, 2.0600000000000023]\n",
      "Step 900 (epoch 1.05), 67.4 ms\n",
      "Minibatch loss: 0.066, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.3799999999999955, 1.3599999999999994, 1.2800000000000011, 1.3199999999999932, 1.3199999999999932]\n",
      "Step 1000 (epoch 1.16), 67.5 ms\n",
      "Minibatch loss: 0.065, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2199999999999989, 1.2000000000000028, 1.1200000000000045, 1.1599999999999966, 1.1200000000000045]\n",
      "Step 1100 (epoch 1.28), 67.5 ms\n",
      "Minibatch loss: 0.010, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.4599999999999937, 1.3400000000000034, 1.4000000000000057, 1.4200000000000017, 1.4000000000000057]\n",
      "Step 1200 (epoch 1.40), 67.5 ms\n",
      "Minibatch loss: 0.068, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 1.5625, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2399999999999949, 1.2199999999999989, 1.2000000000000028, 1.2000000000000028, 1.2000000000000028]\n",
      "Step 1300 (epoch 1.51), 67.4 ms\n",
      "Minibatch loss: 0.061, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.4200000000000017, 1.3199999999999932, 1.3199999999999932, 1.3599999999999994, 1.3400000000000034]\n",
      "Step 1400 (epoch 1.63), 67.5 ms\n",
      "Minibatch loss: 0.175, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 3.125, 0.0, 0.0, 1.5625]\n",
      "Validation error: [1.2199999999999989, 1.3599999999999994, 1.3599999999999994, 1.3799999999999955, 1.3599999999999994]\n",
      "Step 1500 (epoch 1.75), 67.5 ms\n",
      "Minibatch loss: 0.250, learning rate: 0.000950\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.0600000000000023, 1.019999999999996, 1.019999999999996, 1.0, 1.0]\n",
      "Step 1600 (epoch 1.86), 67.5 ms\n",
      "Minibatch loss: 0.019, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2800000000000011, 1.2800000000000011, 1.2399999999999949, 1.2399999999999949, 1.2800000000000011]\n",
      "Step 1700 (epoch 1.98), 67.4 ms\n",
      "Minibatch loss: 0.005, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2999999999999972, 1.3400000000000034, 1.3400000000000034, 1.3599999999999994, 1.3599999999999994]\n",
      "Step 1800 (epoch 2.09), 67.5 ms\n",
      "Minibatch loss: 0.060, learning rate: 0.000902\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.3199999999999932, 1.2199999999999989, 1.2399999999999949, 1.2199999999999989, 1.2199999999999989]\n",
      "Step 1900 (epoch 2.21), 67.5 ms\n",
      "Minibatch loss: 0.022, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0999999999999943, 1.0600000000000023, 1.0, 1.0400000000000063, 1.0]\n",
      "Step 2000 (epoch 2.33), 67.5 ms\n",
      "Minibatch loss: 0.217, learning rate: 0.000902\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.2199999999999989, 1.2000000000000028, 1.2000000000000028, 1.2000000000000028, 1.1800000000000068]\n",
      "Step 2100 (epoch 2.44), 67.5 ms\n",
      "Minibatch loss: 0.036, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 1.0999999999999943, 1.0799999999999983, 1.0799999999999983, 1.0799999999999983]\n",
      "Step 2200 (epoch 2.56), 67.4 ms\n",
      "Minibatch loss: 0.105, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.1200000000000045, 1.1400000000000006, 1.0600000000000023, 1.0600000000000023, 1.019999999999996]\n",
      "Step 2300 (epoch 2.68), 67.4 ms\n",
      "Minibatch loss: 0.365, learning rate: 0.000902\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.1599999999999966, 1.1400000000000006, 1.1599999999999966, 1.1400000000000006, 1.1400000000000006]\n",
      "Step 2400 (epoch 2.79), 67.3 ms\n",
      "Minibatch loss: 0.010, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2000000000000028, 1.1800000000000068, 1.1800000000000068, 1.1800000000000068, 1.1800000000000068]\n",
      "Step 2500 (epoch 2.91), 67.5 ms\n",
      "Minibatch loss: 0.012, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.1599999999999966, 1.1400000000000006, 1.1599999999999966, 1.1599999999999966]\n",
      "Step 2600 (epoch 3.03), 67.5 ms\n",
      "Minibatch loss: 0.082, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 1.5625, 0.0]\n",
      "Validation error: [1.4200000000000017, 1.4599999999999937, 1.4399999999999977, 1.480000000000004, 1.4599999999999937]\n",
      "Step 2700 (epoch 3.14), 67.5 ms\n",
      "Minibatch loss: 0.027, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 1.0400000000000063, 1.0400000000000063, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 2800 (epoch 3.26), 67.5 ms\n",
      "Minibatch loss: 0.029, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0999999999999943, 1.1599999999999966, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045]\n",
      "Step 2900 (epoch 3.37), 67.5 ms\n",
      "Minibatch loss: 0.140, learning rate: 0.000857\n",
      "Minibatch error: [1.5625, 3.125, 1.5625, 1.5625, 0.0]\n",
      "Validation error: [1.1200000000000045, 1.2000000000000028, 1.2199999999999989, 1.2800000000000011, 1.2800000000000011]\n",
      "Step 3000 (epoch 3.49), 67.5 ms\n",
      "Minibatch loss: 0.023, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.9399999999999977, 0.9599999999999937, 0.9200000000000017, 0.9599999999999937]\n",
      "Step 3100 (epoch 3.61), 67.4 ms\n",
      "Minibatch loss: 0.087, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [1.0, 1.0600000000000023, 1.0999999999999943, 1.0799999999999983, 1.0799999999999983]\n",
      "Step 3200 (epoch 3.72), 67.4 ms\n",
      "Minibatch loss: 0.025, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 3300 (epoch 3.84), 67.5 ms\n",
      "Minibatch loss: 0.008, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.3199999999999932, 1.3599999999999994, 1.3599999999999994, 1.3799999999999955, 1.4000000000000057]\n",
      "Step 3400 (epoch 3.96), 67.5 ms\n",
      "Minibatch loss: 0.009, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: [1.0, 1.0400000000000063, 1.019999999999996, 1.019999999999996, 1.019999999999996]\n",
      "Step 3500 (epoch 4.07), 67.5 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0799999999999983, 0.980000000000004, 1.0400000000000063, 1.019999999999996, 1.019999999999996]\n",
      "Step 3600 (epoch 4.19), 67.3 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.8400000000000034, 0.8799999999999955, 0.8599999999999994, 0.8799999999999955]\n",
      "Step 3700 (epoch 4.31), 67.5 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.019999999999996, 0.9399999999999977, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 3800 (epoch 4.42), 67.5 ms\n",
      "Minibatch loss: 0.098, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 3.125, 1.5625, 1.5625, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.980000000000004, 0.8199999999999932, 0.9200000000000017, 0.8400000000000034]\n",
      "Step 3900 (epoch 4.54), 67.5 ms\n",
      "Minibatch loss: 0.052, learning rate: 0.000815\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 1.0, 0.980000000000004, 1.019999999999996, 1.019999999999996]\n",
      "Step 4000 (epoch 4.65), 67.5 ms\n",
      "Minibatch loss: 0.131, learning rate: 0.000815\n",
      "Minibatch error: [1.5625, 0.0, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [0.980000000000004, 1.0, 0.980000000000004, 1.0, 0.980000000000004]\n",
      "Step 4100 (epoch 4.77), 67.4 ms\n",
      "Minibatch loss: 0.049, learning rate: 0.000815\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9399999999999977, 0.9599999999999937, 0.9599999999999937, 0.980000000000004]\n",
      "Step 4200 (epoch 4.89), 67.5 ms\n",
      "Minibatch loss: 0.071, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 1.5625, 1.5625, 0.0, 1.5625]\n",
      "Validation error: [1.0999999999999943, 1.0999999999999943, 1.1599999999999966, 1.0799999999999983, 1.1200000000000045]\n",
      "Step 4300 (epoch 5.00), 67.5 ms\n",
      "Minibatch loss: 0.071, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 1.019999999999996, 1.019999999999996, 1.0600000000000023, 1.0400000000000063]\n",
      "Step 4400 (epoch 5.12), 67.4 ms\n",
      "Minibatch loss: 0.019, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 1.1200000000000045, 1.0600000000000023, 1.0799999999999983, 1.0600000000000023]\n",
      "Step 4500 (epoch 5.24), 67.5 ms\n",
      "Minibatch loss: 0.076, learning rate: 0.000774\n",
      "Minibatch error: [1.5625, 0.0, 1.5625, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 4600 (epoch 5.35), 67.4 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.8599999999999994, 0.8199999999999932, 0.8199999999999932, 0.8400000000000034]\n",
      "Step 4700 (epoch 5.47), 67.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.980000000000004, 0.980000000000004, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 4800 (epoch 5.59), 67.5 ms\n",
      "Minibatch loss: 0.077, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 1.5625, 0.0, 1.5625, 0.0]\n",
      "Validation error: [1.3400000000000034, 1.519999999999996, 1.5799999999999983, 1.6200000000000045, 1.5999999999999943]\n",
      "Step 4900 (epoch 5.70), 67.4 ms\n",
      "Minibatch loss: 0.022, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.8599999999999994, 0.8400000000000034, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 5000 (epoch 5.82), 67.4 ms\n",
      "Minibatch loss: 0.024, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.019999999999996, 1.0400000000000063, 0.9599999999999937, 1.019999999999996, 0.980000000000004]\n",
      "Step 5100 (epoch 5.93), 67.4 ms\n",
      "Minibatch loss: 0.073, learning rate: 0.000774\n",
      "Minibatch error: [1.5625, 1.5625, 0.0, 1.5625, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.0400000000000063, 0.980000000000004, 1.0, 0.980000000000004]\n",
      "Step 5200 (epoch 6.05), 67.4 ms\n",
      "Minibatch loss: 0.024, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.9399999999999977, 0.9000000000000057, 0.9200000000000017, 0.9000000000000057]\n",
      "Step 5300 (epoch 6.17), 67.5 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8599999999999994, 0.9000000000000057, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 5400 (epoch 6.28), 67.4 ms\n",
      "Minibatch loss: 0.038, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 1.5625, 0.0, 1.5625, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9599999999999937, 1.0, 1.0, 1.0]\n",
      "Step 5500 (epoch 6.40), 67.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.980000000000004, 0.980000000000004, 1.0400000000000063, 1.0400000000000063]\n",
      "Step 5600 (epoch 6.52), 67.4 ms\n",
      "Minibatch loss: 0.055, learning rate: 0.000735\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 1.019999999999996, 1.0, 1.019999999999996, 1.019999999999996]\n",
      "Step 5700 (epoch 6.63), 67.4 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8799999999999955, 0.7999999999999972, 0.8400000000000034, 0.7999999999999972]\n",
      "Step 5800 (epoch 6.75), 67.5 ms\n",
      "Minibatch loss: 0.008, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.9200000000000017, 0.9599999999999937, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 5900 (epoch 6.87), 67.4 ms\n",
      "Minibatch loss: 0.008, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 1.0600000000000023, 1.1800000000000068, 1.1200000000000045, 1.1800000000000068]\n",
      "Step 6000 (epoch 6.98), 67.5 ms\n",
      "Minibatch loss: 0.005, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 1.0, 0.9399999999999977, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 6100 (epoch 7.10), 67.4 ms\n",
      "Minibatch loss: 0.007, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.7999999999999972, 0.8199999999999932, 0.7800000000000011]\n",
      "Step 6200 (epoch 7.21), 67.4 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8400000000000034, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 6300 (epoch 7.33), 67.4 ms\n",
      "Minibatch loss: 0.017, learning rate: 0.000698\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7999999999999972, 0.8199999999999932, 0.7999999999999972, 0.7999999999999972]\n",
      "Step 6400 (epoch 7.45), 67.4 ms\n",
      "Minibatch loss: 0.017, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.5600000000000023, 0.5999999999999943, 0.5600000000000023, 0.5600000000000023, 0.5600000000000023]\n",
      "Step 6500 (epoch 7.56), 67.4 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7399999999999949, 0.7199999999999989, 0.6800000000000068, 0.6800000000000068, 0.6800000000000068]\n",
      "Step 6600 (epoch 7.68), 67.4 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.9000000000000057, 0.8799999999999955]\n",
      "Step 6700 (epoch 7.80), 67.5 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.8400000000000034, 0.8400000000000034, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 6800 (epoch 7.91), 67.5 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8599999999999994, 1.0, 0.9599999999999937, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 6900 (epoch 8.03), 67.5 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: [0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8400000000000034]\n",
      "Step 7000 (epoch 8.15), 67.5 ms\n",
      "Minibatch loss: 0.010, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 7100 (epoch 8.26), 67.5 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.8799999999999955, 0.8599999999999994, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 7200 (epoch 8.38), 67.5 ms\n",
      "Minibatch loss: 0.010, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6800000000000068, 0.7399999999999949, 0.7000000000000028, 0.7199999999999989, 0.7199999999999989]\n",
      "Step 7300 (epoch 8.49), 67.4 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7600000000000051, 0.7800000000000011, 0.7600000000000051, 0.7600000000000051, 0.7600000000000051]\n",
      "Step 7400 (epoch 8.61), 67.4 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8599999999999994, 0.8400000000000034, 0.8599999999999994, 0.8199999999999932]\n",
      "Step 7500 (epoch 8.73), 67.5 ms\n",
      "Minibatch loss: 0.007, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.0799999999999983, 1.0600000000000023, 1.1200000000000045, 1.0999999999999943]\n",
      "Step 7600 (epoch 8.84), 67.5 ms\n",
      "Minibatch loss: 0.067, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 0.0, 0.0]\n",
      "Validation error: [1.0600000000000023, 1.0, 0.9000000000000057, 0.980000000000004, 0.8799999999999955]\n",
      "Step 7700 (epoch 8.96), 67.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 7800 (epoch 9.08), 67.3 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.8400000000000034, 0.7999999999999972, 0.8400000000000034, 0.8400000000000034]\n",
      "Step 7900 (epoch 9.19), 67.5 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7199999999999989, 0.7000000000000028, 0.7000000000000028, 0.7399999999999949, 0.7600000000000051]\n",
      "Step 8000 (epoch 9.31), 67.5 ms\n",
      "Minibatch loss: 0.093, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 1.5625]\n",
      "Validation error: [0.7600000000000051, 0.7199999999999989, 0.7800000000000011, 0.7600000000000051, 0.7999999999999972]\n",
      "Step 8100 (epoch 9.43), 67.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.7800000000000011, 0.7600000000000051, 0.7399999999999949, 0.7600000000000051]\n",
      "Step 8200 (epoch 9.54), 67.4 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.6400000000000006, 0.6599999999999966, 0.6599999999999966, 0.6599999999999966, 0.6800000000000068]\n",
      "Step 8300 (epoch 9.66), 67.5 ms\n",
      "Minibatch loss: 0.022, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.8599999999999994, 0.8199999999999932, 0.8400000000000034, 0.7800000000000011]\n",
      "Step 8400 (epoch 9.77), 67.4 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.8199999999999932, 0.9200000000000017, 0.8799999999999955, 0.9200000000000017]\n",
      "Step 8500 (epoch 9.89), 67.4 ms\n",
      "Minibatch loss: 0.012, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Test error: [0.6800000000000068, 0.7900000000000063, 0.7999999999999972, 0.7999999999999972, 0.7900000000000063]\n"
     ]
    }
   ],
   "source": [
    "use_priors = True\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    1e-3,                # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "    train_prediction, loss = apply(train_data_node, training=True, use_priors=use_priors)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
    "                                                   global_step=batch)\n",
    "\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    eval_prediction, _ = apply(eval_data, training=False, use_priors=use_priors)\n",
    "  # Small utility function to evaluate a dataset by feeding batches of data to\n",
    "  # {eval_data} and pulling the results from {eval_predictions}.\n",
    "  # Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(NUM_UNROLL_STEPS, size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[:, begin:end, :] = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[begin:end, ...]})\n",
    "        else:\n",
    "            batch_predictions = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "            predictions[:, begin:, :] = batch_predictions[:, begin - size:, :]\n",
    "    return predictions\n",
    "\n",
    "lines = []\n",
    "\n",
    "# Create a local session to run the training.\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:    \n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    \n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE):\n",
    "      # Compute the offset of the current minibatch in the data.\n",
    "      # Note that we could use better randomization across epochs.\n",
    "      offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "      batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "      batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "      # This dictionary maps the batch data (as a numpy array) to the\n",
    "      # node in the graph it should be fed to.\n",
    "      feed_dict = {train_data_node: batch_data,\n",
    "                   train_labels_node: batch_labels}\n",
    "      # Run the optimizer to update weights.\n",
    "      sess.run(optimizer, feed_dict=feed_dict)\n",
    "      # print some extra information once reach the evaluation frequency\n",
    "      if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        l, lr, predictions = sess.run([loss, learning_rate, train_prediction],\n",
    "                                      feed_dict=feed_dict)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lines.append('Step %d (epoch %.2f), %.1f ms\\n' %\n",
    "              (step, float(step) * BATCH_SIZE / train_size,\n",
    "               1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch loss: %.3f, learning rate: %.6f\\n' % (l, lr))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch error: {}\\n'.format(error_rate(predictions, batch_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Validation error: {}\\n'.format(error_rate(\n",
    "            eval_in_batches(validation_data, sess), validation_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "    print('Test error: {}'.format(test_error))\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(\"\".join(lines))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_step(input_images, prior, batch_size, training, use_priors):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    \n",
    "\n",
    "        \n",
    "    inputs = input_images\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=inputs,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_shape = pool2.get_shape()\n",
    "    num_units_after_conv = pool2_shape[1] * pool2_shape[2] * pool2_shape[3]\n",
    "\n",
    "    pool2_flat = tf.reshape(pool2, [-1, num_units_after_conv])\n",
    "    \n",
    "    if use_priors:\n",
    "        projections = tf.layers.dense(inputs=prior, units=100, activation=tf.nn.relu)\n",
    "        gates = tf.layers.dense(inputs=projections, units=num_units_after_conv, activation=tf.nn.sigmoid)\n",
    "        \n",
    "        gated = tf.multiply(pool2_flat, gates)\n",
    "    else:\n",
    "        gated = pool2_flat\n",
    "    \n",
    "    \n",
    "    dense = tf.layers.dense(inputs=gated, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=training)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dropout, units=NUM_LABELS)\n",
    "    posteriors = tf.nn.softmax(logits)\n",
    "    \n",
    "    return logits, posteriors\n",
    "\n",
    "def apply(input_images, training, use_priors):\n",
    "    results = []\n",
    "    loss = 0.0\n",
    "\n",
    "    batch_size = input_images.get_shape()[0]\n",
    "    priors = tf.constant(numpy.array([[1/NUM_LABELS for _ in range(NUM_LABELS)] for _ in range(batch_size)],\n",
    "                         dtype=numpy.float32))\n",
    "    for step in range(NUM_UNROLL_STEPS):\n",
    "        with tf.variable_scope('one_step', reuse=(step > 0)):\n",
    "            logits, posteriors = model_step(input_images, priors, batch_size, training=training, use_priors=use_priors)\n",
    "        priors = posteriors\n",
    "        results.append((logits, posteriors))\n",
    "        loss += tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=train_labels_node, logits=logits))\n",
    "    return tf.stack([logits for (logits, _) in results]), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Step 0 (epoch 0.00), 3.9 ms\n",
      "Minibatch loss: 10.935, learning rate: 0.001000\n",
      "Minibatch error: [85.9375, 85.9375, 85.9375, 85.9375, 82.8125]\n",
      "Validation error: [90.76, 90.76, 90.76, 90.76, 90.76]\n",
      "Step 100 (epoch 0.12), 50.2 ms\n",
      "Minibatch loss: 0.482, learning rate: 0.001000\n",
      "Minibatch error: [3.125, 1.5625, 6.25, 4.6875, 4.6875]\n",
      "Validation error: [5.920000000000002, 5.920000000000002, 5.900000000000006, 5.900000000000006, 5.900000000000006]\n",
      "Step 200 (epoch 0.23), 49.3 ms\n",
      "Minibatch loss: 0.551, learning rate: 0.001000\n",
      "Minibatch error: [6.25, 4.6875, 4.6875, 3.125, 4.6875]\n",
      "Validation error: [2.760000000000005, 2.799999999999997, 2.799999999999997, 2.799999999999997, 2.799999999999997]\n",
      "Step 300 (epoch 0.35), 49.3 ms\n",
      "Minibatch loss: 0.480, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 3.125, 3.125, 3.125, 3.125]\n",
      "Validation error: [2.6200000000000045, 2.5799999999999983, 2.5799999999999983, 2.5799999999999983, 2.5799999999999983]\n",
      "Step 400 (epoch 0.47), 49.3 ms\n",
      "Minibatch loss: 0.820, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 4.6875, 4.6875, 4.6875, 4.6875]\n",
      "Validation error: [1.9200000000000017, 1.980000000000004, 1.9599999999999937, 1.9599999999999937, 1.9399999999999977]\n",
      "Step 500 (epoch 0.58), 49.3 ms\n",
      "Minibatch loss: 0.987, learning rate: 0.001000\n",
      "Minibatch error: [4.6875, 3.125, 6.25, 4.6875, 4.6875]\n",
      "Validation error: [1.7999999999999972, 1.7999999999999972, 1.7999999999999972, 1.7999999999999972, 1.7999999999999972]\n",
      "Step 600 (epoch 0.70), 49.5 ms\n",
      "Minibatch loss: 0.451, learning rate: 0.001000\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.7000000000000028, 1.7000000000000028, 1.7000000000000028, 1.7000000000000028, 1.7000000000000028]\n",
      "Step 700 (epoch 0.81), 49.4 ms\n",
      "Minibatch loss: 0.099, learning rate: 0.001000\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.6200000000000045, 1.5999999999999943, 1.5799999999999983, 1.5799999999999983, 1.5799999999999983]\n",
      "Step 800 (epoch 0.93), 49.3 ms\n",
      "Minibatch loss: 0.131, learning rate: 0.001000\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 0.0, 1.5625]\n",
      "Validation error: [1.9000000000000057, 1.9000000000000057, 1.9000000000000057, 1.9000000000000057, 1.9000000000000057]\n",
      "Step 900 (epoch 1.05), 49.4 ms\n",
      "Minibatch loss: 0.035, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.6400000000000006, 1.6599999999999966, 1.6599999999999966, 1.6599999999999966, 1.6599999999999966]\n",
      "Step 1000 (epoch 1.16), 49.4 ms\n",
      "Minibatch loss: 0.137, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 0.0, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.2600000000000051, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011, 1.2800000000000011]\n",
      "Step 1100 (epoch 1.28), 49.4 ms\n",
      "Minibatch loss: 0.008, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.4000000000000057, 1.3799999999999955, 1.3799999999999955, 1.3799999999999955, 1.3799999999999955]\n",
      "Step 1200 (epoch 1.40), 49.4 ms\n",
      "Minibatch loss: 0.145, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.3799999999999955, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057]\n",
      "Step 1300 (epoch 1.51), 49.4 ms\n",
      "Minibatch loss: 0.201, learning rate: 0.000950\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 3.125, 0.0]\n",
      "Validation error: [1.4399999999999977, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057, 1.4000000000000057]\n",
      "Step 1400 (epoch 1.63), 49.3 ms\n",
      "Minibatch loss: 0.172, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.1599999999999966, 1.1599999999999966, 1.1599999999999966, 1.1599999999999966, 1.1599999999999966]\n",
      "Step 1500 (epoch 1.75), 49.4 ms\n",
      "Minibatch loss: 0.209, learning rate: 0.000950\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 1.5625, 3.125]\n",
      "Validation error: [1.0600000000000023, 1.019999999999996, 1.0, 1.0, 1.0]\n",
      "Step 1600 (epoch 1.86), 49.4 ms\n",
      "Minibatch loss: 0.016, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1800000000000068, 1.1800000000000068, 1.1800000000000068, 1.1800000000000068, 1.1800000000000068]\n",
      "Step 1700 (epoch 1.98), 49.5 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000950\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2199999999999989, 1.2199999999999989, 1.2199999999999989, 1.2199999999999989, 1.2199999999999989]\n",
      "Step 1800 (epoch 2.09), 49.5 ms\n",
      "Minibatch loss: 0.033, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2000000000000028, 1.2199999999999989, 1.2000000000000028, 1.2000000000000028, 1.2000000000000028]\n",
      "Step 1900 (epoch 2.21), 49.5 ms\n",
      "Minibatch loss: 0.028, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 2000 (epoch 2.33), 49.4 ms\n",
      "Minibatch loss: 0.079, learning rate: 0.000902\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 2100 (epoch 2.44), 49.4 ms\n",
      "Minibatch loss: 0.099, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 3.125, 1.5625, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 1.0, 1.0, 0.980000000000004, 0.980000000000004]\n",
      "Step 2200 (epoch 2.56), 49.4 ms\n",
      "Minibatch loss: 0.039, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1400000000000006, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045]\n",
      "Step 2300 (epoch 2.68), 49.4 ms\n",
      "Minibatch loss: 0.137, learning rate: 0.000902\n",
      "Minibatch error: [3.125, 1.5625, 1.5625, 1.5625, 1.5625]\n",
      "Validation error: [1.0, 0.9599999999999937, 0.980000000000004, 0.980000000000004, 0.980000000000004]\n",
      "Step 2400 (epoch 2.79), 49.4 ms\n",
      "Minibatch loss: 0.028, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1599999999999966, 1.1599999999999966, 1.1599999999999966, 1.1599999999999966, 1.1599999999999966]\n",
      "Step 2500 (epoch 2.91), 49.4 ms\n",
      "Minibatch loss: 0.007, learning rate: 0.000902\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0999999999999943, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 2600 (epoch 3.03), 49.5 ms\n",
      "Minibatch loss: 0.061, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2199999999999989, 1.2199999999999989, 1.2199999999999989, 1.2199999999999989, 1.2199999999999989]\n",
      "Step 2700 (epoch 3.14), 49.5 ms\n",
      "Minibatch loss: 0.020, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.8799999999999955, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 2800 (epoch 3.26), 49.5 ms\n",
      "Minibatch loss: 0.012, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 2900 (epoch 3.37), 49.5 ms\n",
      "Minibatch loss: 0.035, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.8599999999999994, 0.8599999999999994, 0.8400000000000034]\n",
      "Step 3000 (epoch 3.49), 49.6 ms\n",
      "Minibatch loss: 0.014, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 3100 (epoch 3.61), 49.5 ms\n",
      "Minibatch loss: 0.029, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9599999999999937, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 3200 (epoch 3.72), 49.5 ms\n",
      "Minibatch loss: 0.030, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 3300 (epoch 3.84), 49.5 ms\n",
      "Minibatch loss: 0.012, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.0400000000000063, 1.0400000000000063, 1.0600000000000023, 1.0600000000000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3400 (epoch 3.96), 49.5 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000857\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.5400000000000063, 1.5600000000000023, 1.5400000000000063, 1.5400000000000063, 1.5400000000000063]\n",
      "Step 3500 (epoch 4.07), 49.5 ms\n",
      "Minibatch loss: 0.013, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2999999999999972, 1.3400000000000034, 1.3400000000000034, 1.3199999999999932, 1.3199999999999932]\n",
      "Step 3600 (epoch 4.19), 49.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 3700 (epoch 4.31), 49.5 ms\n",
      "Minibatch loss: 0.012, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 0.9200000000000017, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 3800 (epoch 4.42), 49.4 ms\n",
      "Minibatch loss: 0.016, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996]\n",
      "Step 3900 (epoch 4.54), 49.4 ms\n",
      "Minibatch loss: 0.026, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045, 1.1200000000000045]\n",
      "Step 4000 (epoch 4.65), 49.4 ms\n",
      "Minibatch loss: 0.129, learning rate: 0.000815\n",
      "Minibatch error: [1.5625, 3.125, 0.0, 0.0, 1.5625]\n",
      "Validation error: [0.8799999999999955, 0.9000000000000057, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 4100 (epoch 4.77), 49.5 ms\n",
      "Minibatch loss: 0.052, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 1.5625, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996]\n",
      "Step 4200 (epoch 4.89), 49.5 ms\n",
      "Minibatch loss: 0.017, learning rate: 0.000815\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.019999999999996, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 4300 (epoch 5.00), 49.5 ms\n",
      "Minibatch loss: 0.025, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 4400 (epoch 5.12), 49.4 ms\n",
      "Minibatch loss: 0.020, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 4500 (epoch 5.24), 49.3 ms\n",
      "Minibatch loss: 0.018, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 4600 (epoch 5.35), 49.4 ms\n",
      "Minibatch loss: 0.006, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9000000000000057]\n",
      "Step 4700 (epoch 5.47), 49.4 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.1400000000000006, 1.0999999999999943, 1.1200000000000045, 1.0999999999999943, 1.1200000000000045]\n",
      "Step 4800 (epoch 5.59), 49.3 ms\n",
      "Minibatch loss: 0.020, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 4900 (epoch 5.70), 49.4 ms\n",
      "Minibatch loss: 0.016, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8400000000000034, 0.8199999999999932, 0.7999999999999972, 0.7800000000000011, 0.7800000000000011]\n",
      "Step 5000 (epoch 5.82), 49.4 ms\n",
      "Minibatch loss: 0.029, learning rate: 0.000774\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9000000000000057, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 5100 (epoch 5.93), 49.4 ms\n",
      "Minibatch loss: 0.098, learning rate: 0.000774\n",
      "Minibatch error: [1.5625, 1.5625, 1.5625, 0.0, 1.5625]\n",
      "Validation error: [0.980000000000004, 0.9399999999999977, 0.9200000000000017, 0.9200000000000017, 0.9200000000000017]\n",
      "Step 5200 (epoch 6.05), 49.4 ms\n",
      "Minibatch loss: 0.019, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0799999999999983, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 5300 (epoch 6.17), 49.4 ms\n",
      "Minibatch loss: 0.019, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8599999999999994, 0.8400000000000034, 0.8400000000000034, 0.8400000000000034, 0.8400000000000034]\n",
      "Step 5400 (epoch 6.28), 49.6 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8599999999999994, 0.8400000000000034, 0.8400000000000034, 0.8199999999999932]\n",
      "Step 5500 (epoch 6.40), 49.5 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.019999999999996, 1.019999999999996, 1.0400000000000063, 1.0400000000000063]\n",
      "Step 5600 (epoch 6.52), 49.5 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937, 0.9599999999999937]\n",
      "Step 5700 (epoch 6.63), 49.4 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.2600000000000051, 1.2600000000000051, 1.2600000000000051, 1.2600000000000051, 1.2600000000000051]\n",
      "Step 5800 (epoch 6.75), 49.4 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8400000000000034, 0.7999999999999972, 0.7999999999999972, 0.7999999999999972, 0.7999999999999972]\n",
      "Step 5900 (epoch 6.87), 49.4 ms\n",
      "Minibatch loss: 0.027, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9200000000000017, 0.9200000000000017, 0.9000000000000057, 0.9200000000000017]\n",
      "Step 6000 (epoch 6.98), 49.4 ms\n",
      "Minibatch loss: 0.003, learning rate: 0.000735\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8599999999999994, 0.8799999999999955, 0.8599999999999994, 0.8599999999999994, 0.8599999999999994]\n",
      "Step 6100 (epoch 7.10), 49.4 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9200000000000017, 0.9200000000000017, 0.9000000000000057, 0.9000000000000057, 0.9000000000000057]\n",
      "Step 6200 (epoch 7.21), 49.5 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.7399999999999949, 0.7000000000000028, 0.7000000000000028, 0.7000000000000028]\n",
      "Step 6300 (epoch 7.33), 49.6 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 6400 (epoch 7.45), 49.5 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8799999999999955, 0.9200000000000017, 0.9200000000000017, 0.9399999999999977]\n",
      "Step 6500 (epoch 7.56), 49.5 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9200000000000017, 0.9200000000000017, 0.9000000000000057, 0.9000000000000057]\n",
      "Step 6600 (epoch 7.68), 49.5 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Step 6700 (epoch 7.80), 49.5 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7999999999999972, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949]\n",
      "Step 6800 (epoch 7.91), 49.5 ms\n",
      "Minibatch loss: 0.007, learning rate: 0.000698\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: [1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996, 1.019999999999996]\n",
      "Step 6900 (epoch 8.03), 49.5 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.0, 1.0, 1.0, 1.0]\n",
      "Step 7000 (epoch 8.15), 49.4 ms\n",
      "Minibatch loss: 0.046, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 1.5625, 1.5625, 0.0, 0.0]\n",
      "Validation error: [0.980000000000004, 0.980000000000004, 0.980000000000004, 0.980000000000004, 0.980000000000004]\n",
      "Step 7100 (epoch 8.26), 49.4 ms\n",
      "Minibatch loss: 0.005, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7199999999999989, 0.7000000000000028, 0.7000000000000028, 0.7000000000000028, 0.7000000000000028]\n",
      "Step 7200 (epoch 8.38), 49.4 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949, 0.7399999999999949]\n",
      "Step 7300 (epoch 8.49), 49.4 ms\n",
      "Minibatch loss: 0.033, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 1.5625, 0.0, 0.0]\n",
      "Validation error: [1.019999999999996, 1.019999999999996, 1.0, 1.0, 1.0]\n",
      "Step 7400 (epoch 8.61), 49.4 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 7500 (epoch 8.73), 49.4 ms\n",
      "Minibatch loss: 0.011, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.4399999999999977, 1.4399999999999977, 1.4200000000000017, 1.4000000000000057, 1.4000000000000057]\n",
      "Step 7600 (epoch 8.84), 49.4 ms\n",
      "Minibatch loss: 0.028, learning rate: 0.000663\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.9200000000000017, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Step 7700 (epoch 8.96), 49.4 ms\n",
      "Minibatch loss: 0.001, learning rate: 0.000663\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9399999999999977, 0.9200000000000017, 0.9200000000000017, 0.9000000000000057, 0.8799999999999955]\n",
      "Step 7800 (epoch 9.08), 49.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8799999999999955, 0.8400000000000034, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 7900 (epoch 9.19), 49.4 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 1.0, 1.019999999999996, 1.0, 1.0]\n",
      "Step 8000 (epoch 9.31), 49.3 ms\n",
      "Minibatch loss: 0.018, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9000000000000057, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955, 0.8799999999999955]\n",
      "Step 8100 (epoch 9.43), 49.4 ms\n",
      "Minibatch loss: 0.002, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0799999999999983, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023, 1.0600000000000023]\n",
      "Step 8200 (epoch 9.54), 49.3 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.7800000000000011, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932, 0.8199999999999932]\n",
      "Step 8300 (epoch 9.66), 49.3 ms\n",
      "Minibatch loss: 0.004, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [1.0400000000000063, 1.0400000000000063, 1.0400000000000063, 1.0400000000000063, 1.0400000000000063]\n",
      "Step 8400 (epoch 9.77), 49.3 ms\n",
      "Minibatch loss: 0.000, learning rate: 0.000630\n",
      "Minibatch error: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.8599999999999994, 0.8400000000000034, 0.8400000000000034, 0.8400000000000034, 0.8400000000000034]\n",
      "Step 8500 (epoch 9.89), 49.4 ms\n",
      "Minibatch loss: 0.048, learning rate: 0.000630\n",
      "Minibatch error: [1.5625, 0.0, 0.0, 0.0, 0.0]\n",
      "Validation error: [0.9599999999999937, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977, 0.9399999999999977]\n",
      "Test error: [0.9699999999999989, 0.9300000000000068, 0.9300000000000068, 0.9200000000000017, 0.9099999999999966]\n"
     ]
    }
   ],
   "source": [
    "use_priors = True\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    1e-3,                # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,          # Decay step.\n",
    "    0.95,                # Decay rate.\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "    train_prediction, loss = apply(train_data_node, training=True, use_priors=use_priors)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
    "                                                   global_step=batch)\n",
    "\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    eval_prediction, _ = apply(eval_data, training=False, use_priors=use_priors)\n",
    "  # Small utility function to evaluate a dataset by feeding batches of data to\n",
    "  # {eval_data} and pulling the results from {eval_predictions}.\n",
    "  # Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(NUM_UNROLL_STEPS, size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[:, begin:end, :] = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[begin:end, ...]})\n",
    "        else:\n",
    "            batch_predictions = sess.run(\n",
    "                eval_prediction,\n",
    "                feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "            predictions[:, begin:, :] = batch_predictions[:, begin - size:, :]\n",
    "    return predictions\n",
    "\n",
    "lines = []\n",
    "\n",
    "# Create a local session to run the training.\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:    \n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    \n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE):\n",
    "      # Compute the offset of the current minibatch in the data.\n",
    "      # Note that we could use better randomization across epochs.\n",
    "      offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "      batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "      batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "      # This dictionary maps the batch data (as a numpy array) to the\n",
    "      # node in the graph it should be fed to.\n",
    "      feed_dict = {train_data_node: batch_data,\n",
    "                   train_labels_node: batch_labels}\n",
    "      # Run the optimizer to update weights.\n",
    "      sess.run(optimizer, feed_dict=feed_dict)\n",
    "      # print some extra information once reach the evaluation frequency\n",
    "      if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        l, lr, predictions = sess.run([loss, learning_rate, train_prediction],\n",
    "                                      feed_dict=feed_dict)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lines.append('Step %d (epoch %.2f), %.1f ms\\n' %\n",
    "              (step, float(step) * BATCH_SIZE / train_size,\n",
    "               1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch loss: %.3f, learning rate: %.6f\\n' % (l, lr))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Minibatch error: {}\\n'.format(error_rate(predictions, batch_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        lines.append('Validation error: {}\\n'.format(error_rate(\n",
    "            eval_in_batches(validation_data, sess), validation_labels)))\n",
    "        print(lines[-1].strip())\n",
    "        sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "    print('Test error: {}'.format(test_error))\n",
    "\n",
    "# print(\"----------------\")\n",
    "# print(\"\".join(lines))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
